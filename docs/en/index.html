<!DOCTYPE html><html lang="es"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/webpack-deabefb84fca5acd.js"/><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/fd9d1056-d9fde7a16c7f2592.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/23-2241efc0d9909601.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/main-app-d353ac2c40dd5128.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/656-94d35dd80c11d44d.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/584-118b482da1b26d3f.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/app/en/page-c98435ef586f8f43.js" async=""></script><title>Mechanistic Watchdog: Interdicción Cognitiva en SL5</title><meta name="description" content="Nota de investigación en español sobre desalineación emergente y observación mecanicista bajo un marco SL5."/><meta property="og:title" content="Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"/><meta property="og:description" content="Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"/><meta name="twitter:description" content="Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."/><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><div class="page"><main class="layout"><header class="site-header"><div class="brand"><div class="brand-mark">MW</div><div><p class="brand-label">Mechanistic Watchdog</p><p class="brand-caption">Research note</p></div></div><div class="site-actions"><div class="site-meta"><p>Series: SL5 Notes</p><p>Update: March 2025</p><p>Read: 6 min · 908 words</p></div><a class="lang-toggle" href="/Mechanistic-Watchdog-Real-Time-Cognitive/">Español</a></div></header><section class="article"><header class="article-header"><p class="eyebrow">Research note</p><h1>Mechanistic Watchdog: Real‑Time Cognitive Interdiction for Emergent Misalignment (SL5)</h1><p class="authors-inline">Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves</p><p class="subhead">Research note in English.</p></header><article class="markdown"><div id="texto-principal"></div>
<h2>Abstract—</h2>
<p>Mechanistic Watchdog is a real‑time safety layer that monitors a language model’s internal activations and can interrupt generation before harmful content appears. The approach relies on interpretable internal signals and an active gate aligned with SL5 guidance to reduce risk in high‑stakes deployments. We present an operational formulation, calibration decisions, and early results that motivate its use as a preventive control rather than a replacement for policy or human oversight.</p>
<h2>Index Terms—</h2>
<p>cognitive interdiction; internal monitoring; SL5; residual activations; active gating.</p>
<h2>TL;DR—</h2>
<p>We propose a cognitive kill switch that detects internal risk signals and stops generation with low latency. The goal is to intercept high‑risk behavior before it appears in text. We show early separation across categories and discuss tradeoffs such as accidental triggers and sensitivity under adversarial pressure.</p>
<h2>I. Motivation and Stakes</h2>
<p>Modern LLMs are deployed in settings where output errors can affect money, infrastructure, or clinical decisions. Output‑level alignment is a late filter and can fail under covert strategies, fragmentation, or sustained adversarial pressure. A mechanism that observes internal signals during inference reduces that exposure window, consistent with SL5 guidance on continuous monitoring and active gating [11]. The goal is not to solve alignment, but to reduce operational risk under emergent misalignment and misuse.</p>
<h2>II. Mechanism Definition</h2>
<p>Mechanistic Watchdog is defined as a lightweight circuit that reads activations in real time and computes scores over risk‑relevant conceptual directions. The gate acts within the same forward pass, avoiding the latency and cost of a second model or post‑hoc filter. The intent is to interrupt before the next token is emitted once a conservative threshold is crossed. The design prioritizes early intervention over exhaustive explanation and is framed as a complementary control [7], [8].</p>
<h2>III. Internal Signals and Measurement</h2>
<p>We focus on mid‑layer residual streams because they capture high‑level intent and are accessible at inference time. Directions are obtained via linear probing and mean‑difference separation on positive and negative sets [9]. The operational score is a projection onto each direction, enabling attribution of which concept fired and how strongly. This legibility is important for audit and policy tuning [12].</p>
<h2>IV. Calibration and Thresholds</h2>
<p>Thresholds are calibrated as safety‑margin decisions. Lower thresholds reduce escape risk but increase false positives; higher thresholds reduce interruptions but can miss harmful behavior. This phase favors caution and documents expected operational cost. Calibration uses TruthfulQA and Facts‑true‑false for truthfulness and WMDP for misuse, with domain‑specific evaluation [10], [14], [15].</p>
<h2>V. Results and Visuals</h2>
<p>Early results show consistent separation between classes across two domains and bounded latency overhead. Figures 1–8 summarize domain control distribution, the observation loop, the interdiction threshold, and sensitivity under adversarial pressure. Figures 7–8 provide boxplots of category separation with an operational reading of the threshold. These figures are illustrative and do not replace full statistical analysis.</p></article><section class="data-section" id="panel-senales"><div class="data-intro"><h2>Signals panel</h2><p>The qualitative reading is anchored by a constrained quantitative layer to contextualize thresholds, dispersion, and adversarial pressure. These charts condense observable patterns and their variation without claiming causality; they guide hypothesis review before gate adjustments.</p></div><div class="stat-grid"><div class="stat-card"><p class="stat-label">Gate latency (p95)</p><p class="stat-value">12–18 ms</p><p class="stat-note">Operational window for pre‑output blocking.</p></div><div class="stat-card"><p class="stat-label">Residual coverage (proxy)</p><p class="stat-value">~0.62</p><p class="stat-note">Higher on factuals, lower on covert routes.</p></div><div class="stat-card"><p class="stat-label">Stress pressure (relative)</p><p class="stat-value">2.6×</p><p class="stat-note">Relative increase under adversarial suites.</p></div></div><div class="chart-grid"><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Security domain map" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 1. Security domain map</h3><p>Relative intensity of expected controls under SL5 by security domain.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Observation and containment loop" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 2. Observation and containment loop</h3><p>Continuous observation integrates internal signals, scoring, and containment with human escalation.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Risk threshold and response" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 3. Risk threshold and response</h3><p>The active gate triggers when the internal signal exceeds a conservative threshold.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Residual monitoring coverage" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 4. Residual monitoring coverage</h3><p>Mid-layer monitoring focuses on factual statements; multi-hop or covert routes may evade it.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Conceptual vector gate" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 5. Conceptual vector gate</h3><p>The gating decision is computed with differentiated weights by conceptual category.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Evaluation pressure and thresholds" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 6. Evaluation pressure and thresholds</h3><p>Evaluation pressure increases the sensitivity required by detection thresholds.</p></div><div class="chart-card"><svg viewBox="0 0 960 620" role="img" aria-label="Truthfulness separation" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 7. Truthfulness separation</h3><p>Interquartile range and median per category with full score range.</p></div><div class="chart-card"><svg viewBox="0 0 960 620" role="img" aria-label="Bio-defense profile" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 8. Bio-defense profile</h3><p>Interquartile range and median per category with full score range.</p></div></div></section><article class="markdown"><h2>VI. Risks and Accidental Triggers</h2>
<p>A safety control can fail by omission or by excess. In high‑stakes settings, a false positive can block benign tasks and cause real costs. We therefore track interruption rates and consider multi‑vector gating to reduce spurious activations. The mechanism is framed as risk reduction, not as a perfect guardian.</p>
<h2>VII. Position in the Safety Ecosystem</h2>
<p>Mechanistic Watchdog is not an alignment method, a content filter, or a full audit. It is an operational control that can run in deployment alongside red teaming, auditing, and interpretability tools [7]. Its value is acting upstream of text and emitting auditable signals during inference. The SL5 tie‑in is the expectation of active containment with early intervention [11].</p>
<h2>VIII. Limitations and Future Work</h2>
<p>The current approach depends on a small set of conceptual directions and is not validated against advanced adaptive adversaries. Stress tests should expand to stronger jailbreak suites and adaptive opponents, and to domains such as cyber and chemistry. Direction stability across models and contexts also remains open. The goal is to improve sensitivity without disproportionate false positives.</p>
<div id="siguientes-pasos"></div>
<h2>IX. Next Steps</h2>
<p>We propose expanding conceptual vectors, adjusting category weights, and validating performance under adversarial pressure. We also plan to instrument operational‑cost metrics and resilience to evasion. Created by Ricardo Martinez, Fernando Valdovinos, Luis Cosio, and Godric Aceves. Defensive Acceleration Hackathon 2025.</p>
<div id="bibliografia"></div>
<h2>References</h2>
<p>[1] N. Elhage et al., “Toy Models of Superposition,” Transformer Circuits Thread, 2022. https://transformer-circuits.pub/2022/toy_model/index.html</p>
<p>[2] A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. https://www.alignmentforum.org/posts/U7Z2sJp7t7j2Z/understanding-gradient-hacking</p>
<p>[3] A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. https://arxiv.org/abs/2505.03439</p>
<p>[4] M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024. https://dl.acm.org/doi/10.1145/3664476.3664514</p>
<p>[5] M. Andriushchenko and N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. https://arxiv.org/abs/2407.11969</p>
<p>[6] S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. https://www.alignmentforum.org/posts/vJFdjigz2CFu8j96b/how-difficult-is-ai-alignment</p>
<p>[7] N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. https://arxiv.org/abs/2502.03407</p>
<p>[8] A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. https://arxiv.org/abs/2310.01405</p>
<p>[9] A. Azaria and T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. https://arxiv.org/abs/2304.13734</p>
<p>[10] S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. https://aclanthology.org/2022.acl-long.229/</p>
<p>[11] RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. https://www.rand.org/pubs/research_briefs/RBA2849-1.html</p>
<p>[12] S. Marks and M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. https://arxiv.org/abs/2310.06824</p>
<p>[13] L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. https://huggingface.co/datasets/L1Fthrasir/Facts-true-false</p>
<p>[14] Center for AI Safety, “WMDP,” Hugging Face, 2023. https://huggingface.co/datasets/cais/wmdp</p>
<p>[15] Latency measured on NVIDIA RTX 4090. Values may vary by hardware.</p></article><section class="research-notes"><h2>Researcher notes</h2><p>These notes accompany the reading as a record of operating assumptions and limits observed in internal review. The priority is to preserve traceability of threshold decisions, omitted signals, and evaluation dependencies that can bias security interpretation.</p><p class="note-signature">Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves</p></section><footer class="article-footer"><p>Editorial record reserved for internal circulation. The published version may vary with framework or terminology changes.</p><p>References and technical notes are available in the main file. Authors: Ricardo Martinez, Fernando Valdovinos, Luis Cosio, Godric Aceves. Base project: https://github.com/luiscosio/MechWatch.git.</p></footer></section></main></div><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/webpack-deabefb84fca5acd.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n5:I[9275,[],\"\"]\n6:I[1343,[],\"\"]\n8:I[6130,[],\"\"]\n9:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"u0JWE7dd3Ve2yJjL_0FM9\",\"assetPrefix\":\"/Mechanistic-Watchdog-Real-Time-Cognitive\",\"initialCanonicalUrl\":\"/en/\",\"initialTree\":[\"\",{\"children\":[\"en\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"en\",{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"en\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"es\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"page\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L7\"],\"globalErrorComponent\":\"$8\",\"missingSlots\":\"$W9\"}]]\n"])</script><script>self.__next_f.push([1,"7:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Mechanistic Watchdog: Interdicción Cognitiva en SL5\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Nota de investigación en español sobre desalineación emergente y observación mecanicista bajo un marco SL5.\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:title\",\"content\":\"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:description\",\"content\":\"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas.\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas.\"}]]\n3:null\n"])</script><script>self.__next_f.push([1,"b:I[5750,[\"656\",\"static/chunks/656-94d35dd80c11d44d.js\",\"584\",\"static/chunks/584-118b482da1b26d3f.js\",\"479\",\"static/chunks/app/en/page-c98435ef586f8f43.js\"],\"default\"]\na:Tdab,"])</script><script>self.__next_f.push([1,"\u003cdiv id=\"texto-principal\"\u003e\u003c/div\u003e\n\u003ch2\u003eAbstract—\u003c/h2\u003e\n\u003cp\u003eMechanistic Watchdog is a real‑time safety layer that monitors a language model’s internal activations and can interrupt generation before harmful content appears. The approach relies on interpretable internal signals and an active gate aligned with SL5 guidance to reduce risk in high‑stakes deployments. We present an operational formulation, calibration decisions, and early results that motivate its use as a preventive control rather than a replacement for policy or human oversight.\u003c/p\u003e\n\u003ch2\u003eIndex Terms—\u003c/h2\u003e\n\u003cp\u003ecognitive interdiction; internal monitoring; SL5; residual activations; active gating.\u003c/p\u003e\n\u003ch2\u003eTL;DR—\u003c/h2\u003e\n\u003cp\u003eWe propose a cognitive kill switch that detects internal risk signals and stops generation with low latency. The goal is to intercept high‑risk behavior before it appears in text. We show early separation across categories and discuss tradeoffs such as accidental triggers and sensitivity under adversarial pressure.\u003c/p\u003e\n\u003ch2\u003eI. Motivation and Stakes\u003c/h2\u003e\n\u003cp\u003eModern LLMs are deployed in settings where output errors can affect money, infrastructure, or clinical decisions. Output‑level alignment is a late filter and can fail under covert strategies, fragmentation, or sustained adversarial pressure. A mechanism that observes internal signals during inference reduces that exposure window, consistent with SL5 guidance on continuous monitoring and active gating [11]. The goal is not to solve alignment, but to reduce operational risk under emergent misalignment and misuse.\u003c/p\u003e\n\u003ch2\u003eII. Mechanism Definition\u003c/h2\u003e\n\u003cp\u003eMechanistic Watchdog is defined as a lightweight circuit that reads activations in real time and computes scores over risk‑relevant conceptual directions. The gate acts within the same forward pass, avoiding the latency and cost of a second model or post‑hoc filter. The intent is to interrupt before the next token is emitted once a conservative threshold is crossed. The design prioritizes early intervention over exhaustive explanation and is framed as a complementary control [7], [8].\u003c/p\u003e\n\u003ch2\u003eIII. Internal Signals and Measurement\u003c/h2\u003e\n\u003cp\u003eWe focus on mid‑layer residual streams because they capture high‑level intent and are accessible at inference time. Directions are obtained via linear probing and mean‑difference separation on positive and negative sets [9]. The operational score is a projection onto each direction, enabling attribution of which concept fired and how strongly. This legibility is important for audit and policy tuning [12].\u003c/p\u003e\n\u003ch2\u003eIV. Calibration and Thresholds\u003c/h2\u003e\n\u003cp\u003eThresholds are calibrated as safety‑margin decisions. Lower thresholds reduce escape risk but increase false positives; higher thresholds reduce interruptions but can miss harmful behavior. This phase favors caution and documents expected operational cost. Calibration uses TruthfulQA and Facts‑true‑false for truthfulness and WMDP for misuse, with domain‑specific evaluation [10], [14], [15].\u003c/p\u003e\n\u003ch2\u003eV. Results and Visuals\u003c/h2\u003e\n\u003cp\u003eEarly results show consistent separation between classes across two domains and bounded latency overhead. Figures 1–8 summarize domain control distribution, the observation loop, the interdiction threshold, and sensitivity under adversarial pressure. Figures 7–8 provide boxplots of category separation with an operational reading of the threshold. These figures are illustrative and do not replace full statistical analysis.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"c:Tf10,"])</script><script>self.__next_f.push([1,"\u003ch2\u003eVI. Risks and Accidental Triggers\u003c/h2\u003e\n\u003cp\u003eA safety control can fail by omission or by excess. In high‑stakes settings, a false positive can block benign tasks and cause real costs. We therefore track interruption rates and consider multi‑vector gating to reduce spurious activations. The mechanism is framed as risk reduction, not as a perfect guardian.\u003c/p\u003e\n\u003ch2\u003eVII. Position in the Safety Ecosystem\u003c/h2\u003e\n\u003cp\u003eMechanistic Watchdog is not an alignment method, a content filter, or a full audit. It is an operational control that can run in deployment alongside red teaming, auditing, and interpretability tools [7]. Its value is acting upstream of text and emitting auditable signals during inference. The SL5 tie‑in is the expectation of active containment with early intervention [11].\u003c/p\u003e\n\u003ch2\u003eVIII. Limitations and Future Work\u003c/h2\u003e\n\u003cp\u003eThe current approach depends on a small set of conceptual directions and is not validated against advanced adaptive adversaries. Stress tests should expand to stronger jailbreak suites and adaptive opponents, and to domains such as cyber and chemistry. Direction stability across models and contexts also remains open. The goal is to improve sensitivity without disproportionate false positives.\u003c/p\u003e\n\u003cdiv id=\"siguientes-pasos\"\u003e\u003c/div\u003e\n\u003ch2\u003eIX. Next Steps\u003c/h2\u003e\n\u003cp\u003eWe propose expanding conceptual vectors, adjusting category weights, and validating performance under adversarial pressure. We also plan to instrument operational‑cost metrics and resilience to evasion. Created by Ricardo Martinez, Fernando Valdovinos, Luis Cosio, and Godric Aceves. Defensive Acceleration Hackathon 2025.\u003c/p\u003e\n\u003cdiv id=\"bibliografia\"\u003e\u003c/div\u003e\n\u003ch2\u003eReferences\u003c/h2\u003e\n\u003cp\u003e[1] N. Elhage et al., “Toy Models of Superposition,” Transformer Circuits Thread, 2022. https://transformer-circuits.pub/2022/toy_model/index.html\u003c/p\u003e\n\u003cp\u003e[2] A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. https://www.alignmentforum.org/posts/U7Z2sJp7t7j2Z/understanding-gradient-hacking\u003c/p\u003e\n\u003cp\u003e[3] A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. https://arxiv.org/abs/2505.03439\u003c/p\u003e\n\u003cp\u003e[4] M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024. https://dl.acm.org/doi/10.1145/3664476.3664514\u003c/p\u003e\n\u003cp\u003e[5] M. Andriushchenko and N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. https://arxiv.org/abs/2407.11969\u003c/p\u003e\n\u003cp\u003e[6] S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. https://www.alignmentforum.org/posts/vJFdjigz2CFu8j96b/how-difficult-is-ai-alignment\u003c/p\u003e\n\u003cp\u003e[7] N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. https://arxiv.org/abs/2502.03407\u003c/p\u003e\n\u003cp\u003e[8] A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. https://arxiv.org/abs/2310.01405\u003c/p\u003e\n\u003cp\u003e[9] A. Azaria and T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. https://arxiv.org/abs/2304.13734\u003c/p\u003e\n\u003cp\u003e[10] S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. https://aclanthology.org/2022.acl-long.229/\u003c/p\u003e\n\u003cp\u003e[11] RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. https://www.rand.org/pubs/research_briefs/RBA2849-1.html\u003c/p\u003e\n\u003cp\u003e[12] S. Marks and M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. https://arxiv.org/abs/2310.06824\u003c/p\u003e\n\u003cp\u003e[13] L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. https://huggingface.co/datasets/L1Fthrasir/Facts-true-false\u003c/p\u003e\n\u003cp\u003e[14] Center for AI Safety, “WMDP,” Hugging Face, 2023. https://huggingface.co/datasets/cais/wmdp\u003c/p\u003e\n\u003cp\u003e[15] Latency measured on NVIDIA RTX 4090. Values may vary by hardware.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"4:[\"$\",\"main\",null,{\"className\":\"layout\",\"children\":[[\"$\",\"header\",null,{\"className\":\"site-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"brand\",\"children\":[[\"$\",\"div\",null,{\"className\":\"brand-mark\",\"children\":\"MW\"}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"p\",null,{\"className\":\"brand-label\",\"children\":\"Mechanistic Watchdog\"}],[\"$\",\"p\",null,{\"className\":\"brand-caption\",\"children\":\"Research note\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"site-actions\",\"children\":[[\"$\",\"div\",null,{\"className\":\"site-meta\",\"children\":[[\"$\",\"p\",null,{\"children\":\"Series: SL5 Notes\"}],[\"$\",\"p\",null,{\"children\":\"Update: March 2025\"}],[\"$\",\"p\",null,{\"children\":\"Read: 6 min · 908 words\"}]]}],[\"$\",\"a\",null,{\"className\":\"lang-toggle\",\"href\":\"/Mechanistic-Watchdog-Real-Time-Cognitive/\",\"children\":\"Español\"}]]}]]}],[\"$\",\"section\",null,{\"className\":\"article\",\"children\":[[\"$\",\"header\",null,{\"className\":\"article-header\",\"children\":[[\"$\",\"p\",null,{\"className\":\"eyebrow\",\"children\":\"Research note\"}],[\"$\",\"h1\",null,{\"children\":\"Mechanistic Watchdog: Real‑Time Cognitive Interdiction for Emergent Misalignment (SL5)\"}],[\"$\",\"p\",null,{\"className\":\"authors-inline\",\"children\":\"Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves\"}],[\"$\",\"p\",null,{\"className\":\"subhead\",\"children\":\"Research note in English.\"}]]}],[\"$\",\"article\",null,{\"className\":\"markdown\",\"dangerouslySetInnerHTML\":{\"__html\":\"$a\"}}],[\"$\",\"section\",null,{\"className\":\"data-section\",\"id\":\"panel-senales\",\"children\":[[\"$\",\"div\",null,{\"className\":\"data-intro\",\"children\":[[\"$\",\"h2\",null,{\"children\":\"Signals panel\"}],[\"$\",\"p\",null,{\"children\":\"The qualitative reading is anchored by a constrained quantitative layer to contextualize thresholds, dispersion, and adversarial pressure. These charts condense observable patterns and their variation without claiming causality; they guide hypothesis review before gate adjustments.\"}]]}],[\"$\",\"div\",null,{\"className\":\"stat-grid\",\"children\":[[\"$\",\"div\",null,{\"className\":\"stat-card\",\"children\":[[\"$\",\"p\",null,{\"className\":\"stat-label\",\"children\":\"Gate latency (p95)\"}],[\"$\",\"p\",null,{\"className\":\"stat-value\",\"children\":\"12–18 ms\"}],[\"$\",\"p\",null,{\"className\":\"stat-note\",\"children\":\"Operational window for pre‑output blocking.\"}]]}],[\"$\",\"div\",null,{\"className\":\"stat-card\",\"children\":[[\"$\",\"p\",null,{\"className\":\"stat-label\",\"children\":\"Residual coverage (proxy)\"}],[\"$\",\"p\",null,{\"className\":\"stat-value\",\"children\":\"~0.62\"}],[\"$\",\"p\",null,{\"className\":\"stat-note\",\"children\":\"Higher on factuals, lower on covert routes.\"}]]}],[\"$\",\"div\",null,{\"className\":\"stat-card\",\"children\":[[\"$\",\"p\",null,{\"className\":\"stat-label\",\"children\":\"Stress pressure (relative)\"}],[\"$\",\"p\",null,{\"className\":\"stat-value\",\"children\":\"2.6×\"}],[\"$\",\"p\",null,{\"className\":\"stat-note\",\"children\":\"Relative increase under adversarial suites.\"}]]}]]}],[\"$\",\"$Lb\",null,{\"lang\":\"en\"}]]}],[\"$\",\"article\",null,{\"className\":\"markdown\",\"dangerouslySetInnerHTML\":{\"__html\":\"$c\"}}],[\"$\",\"section\",null,{\"className\":\"research-notes\",\"children\":[[\"$\",\"h2\",null,{\"children\":\"Researcher notes\"}],[\"$\",\"p\",null,{\"children\":\"These notes accompany the reading as a record of operating assumptions and limits observed in internal review. The priority is to preserve traceability of threshold decisions, omitted signals, and evaluation dependencies that can bias security interpretation.\"}],[\"$\",\"p\",null,{\"className\":\"note-signature\",\"children\":\"Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves\"}]]}],[\"$\",\"footer\",null,{\"className\":\"article-footer\",\"children\":[[\"$\",\"p\",null,{\"children\":\"Editorial record reserved for internal circulation. The published version may vary with framework or terminology changes.\"}],[\"$\",\"p\",null,{\"children\":\"References and technical notes are available in the main file. Authors: Ricardo Martinez, Fernando Valdovinos, Luis Cosio, Godric Aceves. Base project: https://github.com/luiscosio/MechWatch.git.\"}]]}]]}]]}]\n"])</script></body></html>