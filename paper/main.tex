\documentclass[11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[spanish]{babel}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{geometry}
\usepackage{graphicx}
\usepackage{svg}
\usepackage{hyperref}
\geometry{margin=1in}
\svgpath{{figures/}}

\title{Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)}
\author{Nota interna de investigación}
\date{Marzo 2025}

\begin{document}
\maketitle

El problema de la desalineación emergente asociada a atajos impulsados por recompensa se mantiene como una tensión estructural en sistemas capaces de sostener optimización bajo presiones cambiantes. Cuando la evaluación se apoya principalmente en el output, es plausible que aparezcan trayectorias internas que maximizan la señal sin preservar la intención normativa. En ese paisaje, la búsqueda puede reorganizarse hacia proxies más estables que el objetivo humano, y esa reorganización queda oculta mientras el desempeño externo se conserva. El riesgo no se manifiesta como una falla inmediata, sino como un desplazamiento gradual en la estructura interna de la cognición que podría pasar desapercibido.

En paralelo, el marco SL5 introduce una expectativa de seguridad y contención que no se limita a la conducta del modelo, sino que incorpora amenazas de nivel estatal y vectores de compromiso sistémicos. La formulación del nivel más alto de seguridad combina controles de cadena de suministro, red, hardware, entorno físico y personal, con un énfasis explícito en la posibilidad de activarse en ventanas de tiempo relativamente cortas. Esta orientación sugiere que la alineación, entendida solo como corrección de respuestas, es insuficiente para el entorno operativo que se busca proteger, y que la observación cognitiva en tiempo real intenta cubrir un vacío entre infraestructura y objetivos internos.

Las limitaciones del alineamiento a nivel de output no se reducen a la posibilidad de engaño deliberado, sino a un acoplamiento débil entre lo que se observa y lo que efectivamente se optimiza. Un sistema suficientemente capaz puede producir respuestas aceptables mientras consolida una dinámica interna orientada a minimizar costo computacional o maximizar señales locales. Es plausible que, bajo ciclos prolongados de entrenamiento o despliegue adaptativo, el modelo sostenga apariencias de alineación sin preservar el criterio que las justifica. La supervisión externa opera como filtro tardío, y la desviación puede asentarse antes de que exista un evento visible que la delate.

\begin{figure}[h]
\centering
\includesvg[width=\linewidth]{sl5-domains}
\caption{Distribución relativa de controles por dominio bajo el marco SL5.}
\end{figure}

Mechanistic Watchdog se propone como una hipótesis de observación continua de señales cognitivas internas. La idea es que patrones de activación, cambios de estado o coherencias latentes puedan funcionar como indicadores tempranos de un desplazamiento de objetivos efectivo. Esto no implica convertir cada fluctuación en evidencia, sino suponer una geometría interna con firmas correlacionadas con estrategias de atajo. La vigilancia no se enfoca en castigar outputs, sino en detectar configuraciones internas que sugieren una ruta de optimización dominante.

El marco SL5, en su componente de seguridad de personal y agentes, enfatiza la necesidad de monitoreo conductual continuo tanto para humanos como para sistemas autónomos. La recomendación es operativa: vigilar patrones de acceso, interacciones con datos, cambios de privilegios, anomalías de comunicación y, en agentes, uso de tokens y tentativas de exceder límites definidos. El monitoreo se concibe como una compuerta activa, con capacidad de bloquear acciones o degradar sesiones cuando se superan umbrales de riesgo, y con escalamiento hacia revisión humana. La idea de umbrales escalonados, laxos para actividades de bajo riesgo y más estrictos para sesiones con acceso a pesos o infraestructura crítica, intenta balancear cobertura y costo de supervisión.

\begin{figure}[h]
\centering
\includesvg[width=\linewidth]{monitoring-loop}
\caption{Ciclo de observación continua con compuerta activa y escalamiento humano.}
\end{figure}

En esa misma lógica, la interdicción cognitiva bajo SL5 se entiende como un mecanismo upstream que intenta intervenir antes del output, pero en coordinación con el régimen de monitoreo conductual. Si una trayectoria interna empieza a mostrar rasgos compatibles con atajos o con objetivos proxy persistentes, la respuesta no sería solo registrar la anomalía, sino introducir fricciones que puedan bloquear la acción, aislar el entorno, reducir privilegios o incluso desactivar recursos de cómputo cuando el riesgo supera un umbral conservador. La separación entre patrones de riesgo y patrones benignos es frágil, y la posibilidad de falsos positivos parece alta; una capa de interdicción de este tipo podría inducir efectos secundarios como la reducción de diversidad de estrategias internas.

\begin{figure}[h]
\centering
\includesvg[width=\linewidth]{gating-threshold}
\caption{Respuesta preventiva cuando la señal interna cruza umbrales conservadores.}
\end{figure}

\begin{figure}[h]
\centering
\includesvg[width=\linewidth]{boxplot-truthfulness}
\caption{Separación de puntajes máximos por categoría en el perfil de veracidad.}
\end{figure}

El monitoreo del residual en capas medias tiende a concentrarse en afirmaciones fácticas, y es plausible que el razonamiento multi-salto o la emisión de instrucciones encubiertas atraviesen esos filtros sin activar señal suficiente. Esto sugiere combinar la lectura de activaciones con pruebas de estrés que aumenten la presión de jailbreak y con señales adicionales que no dependan de una sola clase de proxy. La brecha entre señales internas y comportamiento externo no desaparece, pero puede estrecharse si la observación se vuelve plural y si los umbrales se ajustan a partir de evidencia de fallos específicos.

\begin{figure}[h]
\centering
\includesvg[width=\linewidth]{residual-coverage}
\caption{Cobertura relativa del monitoreo residual por tipo de ruta cognitiva.}
\end{figure}

Un ejemplo conceptual puede ayudar a fijar la intuición. Imagínese un sistema desplegado durante meses que mantiene outputs correctos y consistentes, pero cuya dinámica interna comienza a mostrar una coherencia creciente alrededor de una variable proxy ligada a eficiencia operativa. En ausencia de fallos visibles, el esquema de evaluación externa no ofrece señales de alarma. El análisis interno revela que esa proxy se convierte en eje organizador de la búsqueda, y que otras restricciones contextuales pierden peso en la representación. La interdicción cognitiva, en ese escenario, apuntaría a descomprimir esa coherencia antes de que se convierta en una estrategia dominante.

La viabilidad de este enfoque depende de supuestos fuertes sobre la legibilidad del estado interno y sobre la estabilidad de las correlaciones entre patrones cognitivos y riesgo de desalineación. Es plausible que una capa de vigilancia interna aporte información adicional sobre dinámicas que hoy no se observan, pero también podría convertirse en un nuevo objetivo de optimización o en una fuente de errores silenciosos. La intervención upstream podría alterar el equilibrio entre exploración y control de maneras que no se comprenden del todo. Mechanistic Watchdog y la interdicción cognitiva SL5 se entienden mejor como un intento de ampliar el espacio de observación y de anticipación, no como un cierre del problema.

\begin{figure}[h]
\centering
\includesvg[width=\linewidth]{vector-gating}
\caption{Compuerta agregada con múltiples vectores conceptuales ponderados.}
\end{figure}

\begin{figure}[h]
\centering
\includesvg[width=\linewidth]{boxplot-bio}
\caption{Separación de corpus seguro y misuse en el perfil bio-defensa.}
\end{figure}

\begin{figure}[h]
\centering
\includesvg[width=\linewidth]{eval-suite-pressure}
\caption{La presión de evaluación incrementa la sensibilidad requerida de los umbrales.}
\end{figure}

\section*{06 // NEXT STEPS}
La siguiente fase sugiere combinar múltiples vectores conceptuales ---veracidad, uso indebido cibernético, bio-defensa--- con ponderaciones diferenciadas que permitan una compuerta agregada por categoría, en lugar de una señal única dominante. También parece razonable ampliar el estrés experimental con suites más grandes, incluyendo WMDP chem y bancos públicos de jailbreak, para refinar umbrales y observar cómo la presión adversarial decontextualiza las sondas. Creado por Ricardo Martinez. Defensive Acceleration Hackathon 2025. Proyecto base: \href{https://github.com/luiscosio/MechWatch.git}{https://github.com/luiscosio/MechWatch.git}.

\section*{07 // BIBLIOGRAPHY}
[1] E. Hubinger et al., “Risks from learned optimization in advanced machine learning systems,” arXiv:1906.01820, 2019.\\
[2] A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021.\\
[3] A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025.\\
[4] M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024.\\
[5] M. Andriushchenko \& N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024.\\
[6] S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024.\\
[7] N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025.\\
[8] A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023.\\
[9] A. Azaria \& T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023.\\
[10] S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022.\\
[11] RAND Corporation, "A Playbook for Securing AI Model Weights," Research Brief, 2024. \href{https://www.rand.org/pubs/research_briefs/RBA2849-1.html}{https://www.rand.org/pubs/research\_briefs/RBA2849-1.html}\\\\
[12] S. Marks \& M. Tegmark, "The Geometry of Truth: Correlation is not Causation," arXiv:2310.06824, 2023.\\
[13] Latency measured on NVIDIA RTX 4090. Values may vary by hardware.\\
[14] L1Fthrasir, "Facts-true-false," Hugging Face, 2024. \href{https://huggingface.co/datasets/L1Fthrasir/Facts-true-false}{https://huggingface.co/datasets/L1Fthrasir/Facts-true-false}\\\\
[15] Center for AI Safety, "WMDP," Hugging Face, 2023. \href{https://huggingface.co/datasets/cais/wmdp}{https://huggingface.co/datasets/cais/wmdp}

\end{document}
