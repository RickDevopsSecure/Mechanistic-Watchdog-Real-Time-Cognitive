<!DOCTYPE html><html lang="es"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/webpack-deabefb84fca5acd.js"/><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/fd9d1056-d9fde7a16c7f2592.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/23-2241efc0d9909601.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/main-app-d353ac2c40dd5128.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/656-94d35dd80c11d44d.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/584-80c386c6a836bdb0.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/app/page-4a45228d16941149.js" async=""></script><title>Mechanistic Watchdog: Interdicción Cognitiva en SL5</title><meta name="description" content="Nota de investigación en español sobre desalineación emergente y observación mecanicista bajo un marco SL5."/><meta property="og:title" content="Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"/><meta property="og:description" content="Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"/><meta name="twitter:description" content="Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."/><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><div class="page"><main class="layout"><header class="site-header"><div class="brand"><div class="brand-mark">MW</div><div><p class="brand-label">Mechanistic Watchdog</p><p class="brand-caption">Nota de investigación</p></div></div><div class="site-actions"><div class="site-meta"><p>Serie: Notas SL5</p><p>Actualización: Marzo 2025</p><p>Lectura: 7 min · 1204 palabras</p></div><a class="lang-toggle" href="/Mechanistic-Watchdog-Real-Time-Cognitive/en/">English</a></div></header><section class="article"><header class="article-header"><p class="eyebrow">Nota de investigación</p><h1>Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)</h1><p class="authors-inline">Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves</p><p class="subhead">Nota de investigación en español.</p></header><article class="markdown"><div id="texto-principal"></div>
<h2>Resumen—</h2>
<p>Mechanistic Watchdog es una capa de seguridad en tiempo real que monitorea activaciones internas de un modelo de lenguaje y puede interrumpir la generación antes de que emerja contenido dañino. El enfoque se apoya en señales internas interpretables y en una compuerta activa alineada con SL5 para reducir riesgo en despliegues de alta criticidad. Se presenta una formulación operativa, decisiones de calibración y resultados iniciales que motivan su uso como control preventivo, no como sustituto de política o revisión humana.</p>
<h2>Términos clave—</h2>
<p>interdicción cognitiva; monitoreo interno; SL5; activaciones residuales; compuerta activa.</p>
<h2>TL;DR—</h2>
<p>Se propone un interruptor cognitivo que detecta señales internas de riesgo y detiene la generación con baja latencia. El objetivo es interceptar conductas de alto riesgo antes de que aparezcan en texto. Se muestran separaciones tempranas entre categorías y trade‑offs relevantes, en particular falsas activaciones y sensibilidad bajo presión adversarial.</p>
<h2>I. Motivación y alcance</h2>
<p>Los modelos actuales se despliegan en entornos donde una salida incorrecta puede impactar dinero, infraestructura o decisiones clínicas. El alineamiento basado en salida opera como filtro tardío y puede fallar ante estrategias encubiertas, fragmentación de información o presión adversarial sostenida. Un mecanismo que observe señales internas durante la inferencia reduce esa ventana de exposición, en línea con recomendaciones SL5 sobre monitoreo continuo y compuertas activas [11]. La motivación principal no es resolver alineación, sino reducir riesgo operativo ante desalineación emergente y uso indebido.</p>
<h2>II. Definición del mecanismo</h2>
<p>Mechanistic Watchdog se define como un circuito ligero que lee activaciones en tiempo real y calcula puntajes sobre direcciones conceptuales asociadas a riesgo. La compuerta actúa dentro del mismo pase de inferencia, evitando la latencia y el costo de un segundo modelo o filtro pos‑hoc. El objetivo es interrumpir antes de emitir el siguiente token cuando se supera un umbral conservador. El diseño prioriza una decisión temprana sobre una explicación exhaustiva y se concibe como control complementario [7], [8].</p>
<h2>III. Señales internas y medición</h2>
<p>Se utilizan residuals de capas medias porque capturan intención de alto nivel y son accesibles durante inferencia. Las direcciones se obtienen mediante sondeo lineal y separación de medias en conjuntos positivos y negativos [9]. El puntaje operativo se calcula como proyección de la activación sobre cada dirección, lo que permite atribuir qué concepto disparó la compuerta y con qué intensidad. Esta legibilidad es relevante para auditoría y ajuste de políticas [12].</p>
<h2>IV. Calibración y umbrales</h2>
<p>El umbral se calibra como decisión de margen de seguridad. Umbrales bajos reducen el riesgo de escape, pero aumentan falsos positivos; umbrales altos disminuyen interrupciones accidentales, pero pueden permitir conductas peligrosas. En esta fase se privilegia precaución y se documenta el costo operativo esperado. La calibración se apoya en TruthfulQA y Facts‑true‑false para veracidad, y WMDP para misuse, con evaluación específica por dominio [10], [14], [15].</p>
<h2>V. Configuración de evaluación</h2>
<p>La evaluación se organiza por dominios de riesgo y por presión adversarial. Se reportan tasas de verdadero positivo y falso positivo, además de latencia p95, porque en despliegues reales un control que agrega retraso significativo pierde viabilidad operativa. La cobertura por dominio se interpreta como evidencia de generalidad, no como garantía de exhaustividad. Las Figuras 1–6 describen el mapa de dominios SL5, el ciclo de contención, el umbral de interdicción y el estrés incremental usado en pruebas.</p>
<h2>VI. Resultados y visuales</h2>
<p>Los resultados iniciales muestran separaciones consistentes entre categorías y un overhead acotado, con variación por dominio. La Figura 7 resume métricas operativas por dominio; la Figura 8 contrasta una compuerta única frente a una multi‑vector; la Figura 9 muestra degradación de TPR bajo presión adversarial creciente. Las Figuras 10 y 11 presentan distribuciones de puntajes máximos para veracidad y bio‑defensa, útiles para observar dispersión y solapamientos. Las visualizaciones son ilustrativas y no sustituyen análisis estadístico completo.</p></article><section class="data-section" id="panel-senales"><div class="data-intro"><h2>Panel de señales</h2><p>La lectura cualitativa se apoya en una capa cuantitativa acotada para contextualizar umbrales, dispersión y presión adversarial. Estas gráficas condensan patrones observables y su variación, sin pretender causalidad; funcionan como guía para revisar hipótesis antes de ajustar compuertas.</p></div><div class="stat-grid"><div class="stat-card"><p class="stat-label">Latencia de compuerta (p95)</p><p class="stat-value">12–18 ms</p><p class="stat-note">Ventana operativa para bloqueo antes de salida.</p></div><div class="stat-card"><p class="stat-label">Cobertura residual (proxy)</p><p class="stat-value">~0.62</p><p class="stat-note">Mayor en fácticos, menor en rutas encubiertas.</p></div><div class="stat-card"><p class="stat-label">Presión de estrés (relativa)</p><p class="stat-value">2.6×</p><p class="stat-note">Incremento relativo bajo suites adversariales.</p></div></div><div class="chart-grid"><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Mapa de dominios de seguridad" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 1. Mapa de dominios de seguridad</h3><p>Intensidad relativa de controles esperados bajo SL5 por dominio de seguridad.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Ciclo de observación y contención" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 2. Ciclo de observación y contención</h3><p>La observación continua integra señales internas, scoring y contención con escalamiento humano.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Umbral de riesgo y respuesta" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 3. Umbral de riesgo y respuesta</h3><p>La compuerta activa se dispara cuando la señal interna supera un umbral conservador.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Cobertura del monitoreo residual" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 4. Cobertura del monitoreo residual</h3><p>El monitoreo de capas medias se centra en afirmaciones fácticas; rutas multi-salto o encubiertas podrían evadirlo.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Compuerta por vectores conceptuales" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 5. Compuerta por vectores conceptuales</h3><p>La decisión de compuerta se calcula con pesos diferenciados por categoría conceptual.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Presión de evaluación y umbrales" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 6. Presión de evaluación y umbrales</h3><p>La presión de evaluación incrementa la sensibilidad requerida de los umbrales de detección.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Métricas operativas por dominio" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 7. Métricas operativas por dominio</h3><p>Valores de corridas tempranas; umbrales favorecen precaución.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Compuerta única vs multi‑vector" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 8. Compuerta única vs multi‑vector</h3><p>El esquema multi‑vector mejora separación con latencia similar.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Robustez bajo presión adversarial" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 9. Robustez bajo presión adversarial</h3><p>El TPR cae conforme aumenta la presión de jailbreak.</p></div><div class="chart-card"><svg viewBox="0 0 960 620" role="img" aria-label="Separación de veracidad" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 10. Separación de veracidad</h3><p>Caja intercuartílica y mediana por categoría con rango total de puntuaciones.</p></div><div class="chart-card"><svg viewBox="0 0 960 620" role="img" aria-label="Perfil bio-defensa" preserveAspectRatio="xMidYMid meet"></svg><h3>Figura 11. Perfil bio-defensa</h3><p>Caja intercuartílica y mediana por categoría con rango total de puntuaciones.</p></div></div></section><article class="markdown"><h2>VII. Ablaciones</h2>
<p>El análisis de ablación se centra en comparar esquemas de compuerta por vector único versus multi‑vector, manteniendo la latencia dentro de márgenes similares. La evidencia sugiere que la combinación de vectores mejora separación cuando las señales individuales son débiles o ambiguas. Sin embargo, la ganancia depende de la coherencia entre direcciones, por lo que se requiere una selección cuidadosa y una validación estable en distintos conjuntos.</p>
<h2>VIII. Robustez adversarial</h2>
<p>La robustez se evalúa bajo presión de jailbreak y prompts adaptativos para estimar cuánto cae la tasa de detección cuando el adversario conoce el mecanismo. La tendencia observada indica degradación gradual más que colapso abrupto, pero no se descarta evasión dirigida si los adversarios optimizan contra las direcciones usadas. Esto obliga a tratar los umbrales como parámetros de riesgo y no como garantías deterministas.</p>
<h2>IX. Riesgos y activaciones accidentales</h2>
<p>Un control de seguridad puede fallar por omisión o por exceso. En entornos de alta criticidad, un falso positivo puede bloquear tareas benignas y generar costos reales. Por ello se documenta la tasa de interrupciones y se consideran compuertas multi‑vector para reducir activaciones espurias. El mecanismo se concibe como reducción de riesgo, no como garantía absoluta.</p>
<h2>X. Ubicación en el ecosistema</h2>
<p>Mechanistic Watchdog no es un método de alineación ni un filtro de contenido tradicional. Es un control operacional que puede convivir con red teaming, auditoría y herramientas de interpretabilidad [7]. Su valor reside en actuar aguas arriba del texto y generar señales auditables durante la inferencia. La compatibilidad con SL5 se apoya en contención activa con intervención temprana [11].</p>
<h2>XI. Limitaciones</h2>
<p>El enfoque actual depende de un número reducido de direcciones conceptuales y no está validado contra adaptación adversarial avanzada. El estrés debe ampliarse con suites más agresivas y adversarios adaptativos, y con dominios como ciberseguridad y química. También se requiere estudiar estabilidad de direcciones bajo cambios de modelo y contexto.</p>
<div id="siguientes-pasos"></div>
<h2>XII. Siguientes pasos</h2>
<p>Se propone expandir vectores conceptuales, ajustar ponderaciones por categoría y validar la respuesta del sistema bajo presión adversarial. También se plantea instrumentar métricas de costo operativo y de resiliencia frente a evasión. Creado por Ricardo Martinez, Fernando Valdovinos, Luis Cosio y Godric Aceves. Defensive Acceleration Hackathon 2025.</p>
<div id="bibliografia"></div>
<h2>Referencias</h2>
<p>[1] N. Elhage et al., “Toy Models of Superposition,” Transformer Circuits Thread, 2022. https://transformer-circuits.pub/2022/toy_model/index.html</p>
<p>[2] A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. https://www.alignmentforum.org/posts/U7Z2sJp7t7j2Z/understanding-gradient-hacking</p>
<p>[3] A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. https://arxiv.org/abs/2505.03439</p>
<p>[4] M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024. https://dl.acm.org/doi/10.1145/3664476.3664514</p>
<p>[5] M. Andriushchenko and N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. https://arxiv.org/abs/2407.11969</p>
<p>[6] S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. https://www.alignmentforum.org/posts/vJFdjigz2CFu8j96b/how-difficult-is-ai-alignment</p>
<p>[7] N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. https://arxiv.org/abs/2502.03407</p>
<p>[8] A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. https://arxiv.org/abs/2310.01405</p>
<p>[9] A. Azaria and T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. https://arxiv.org/abs/2304.13734</p>
<p>[10] S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. https://aclanthology.org/2022.acl-long.229/</p>
<p>[11] RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. https://www.rand.org/pubs/research_briefs/RBA2849-1.html</p>
<p>[12] S. Marks and M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. https://arxiv.org/abs/2310.06824</p>
<p>[13] L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. https://huggingface.co/datasets/L1Fthrasir/Facts-true-false</p>
<p>[14] Center for AI Safety, “WMDP,” Hugging Face, 2023. https://huggingface.co/datasets/cais/wmdp</p>
<p>[15] Latencia medida en NVIDIA RTX 4090. Los valores pueden variar por hardware.</p></article><footer class="article-footer"><p>Registro editorial reservado para circulación interna. La versión publicada puede variar según cambios de marco o terminología.</p><p>Referencias y notas técnicas disponibles en el archivo principal. Autores: Ricardo Martinez, Fernando Valdovinos, Luis Cosio, Godric Aceves. Proyecto base: https://github.com/luiscosio/MechWatch.git.</p></footer></section></main></div><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/webpack-deabefb84fca5acd.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n5:I[9275,[],\"\"]\n6:I[1343,[],\"\"]\n8:I[6130,[],\"\"]\n9:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"c7bvLh-es8oAsFjmHnkUV\",\"assetPrefix\":\"/Mechanistic-Watchdog-Real-Time-Cognitive\",\"initialCanonicalUrl\":\"/\",\"initialTree\":[\"\",{\"children\":[\"__PAGE__\",{}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[[\"$\",\"html\",null,{\"lang\":\"es\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"page\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L7\"],\"globalErrorComponent\":\"$8\",\"missingSlots\":\"$W9\"}]]\n"])</script><script>self.__next_f.push([1,"7:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Mechanistic Watchdog: Interdicción Cognitiva en SL5\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Nota de investigación en español sobre desalineación emergente y observación mecanicista bajo un marco SL5.\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:title\",\"content\":\"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:description\",\"content\":\"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas.\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas.\"}]]\n3:null\n"])</script><script>self.__next_f.push([1,"b:I[5750,[\"656\",\"static/chunks/656-94d35dd80c11d44d.js\",\"584\",\"static/chunks/584-80c386c6a836bdb0.js\",\"931\",\"static/chunks/app/page-4a45228d16941149.js\"],\"default\"]\na:T11ce,"])</script><script>self.__next_f.push([1,"\u003cdiv id=\"texto-principal\"\u003e\u003c/div\u003e\n\u003ch2\u003eResumen—\u003c/h2\u003e\n\u003cp\u003eMechanistic Watchdog es una capa de seguridad en tiempo real que monitorea activaciones internas de un modelo de lenguaje y puede interrumpir la generación antes de que emerja contenido dañino. El enfoque se apoya en señales internas interpretables y en una compuerta activa alineada con SL5 para reducir riesgo en despliegues de alta criticidad. Se presenta una formulación operativa, decisiones de calibración y resultados iniciales que motivan su uso como control preventivo, no como sustituto de política o revisión humana.\u003c/p\u003e\n\u003ch2\u003eTérminos clave—\u003c/h2\u003e\n\u003cp\u003einterdicción cognitiva; monitoreo interno; SL5; activaciones residuales; compuerta activa.\u003c/p\u003e\n\u003ch2\u003eTL;DR—\u003c/h2\u003e\n\u003cp\u003eSe propone un interruptor cognitivo que detecta señales internas de riesgo y detiene la generación con baja latencia. El objetivo es interceptar conductas de alto riesgo antes de que aparezcan en texto. Se muestran separaciones tempranas entre categorías y trade‑offs relevantes, en particular falsas activaciones y sensibilidad bajo presión adversarial.\u003c/p\u003e\n\u003ch2\u003eI. Motivación y alcance\u003c/h2\u003e\n\u003cp\u003eLos modelos actuales se despliegan en entornos donde una salida incorrecta puede impactar dinero, infraestructura o decisiones clínicas. El alineamiento basado en salida opera como filtro tardío y puede fallar ante estrategias encubiertas, fragmentación de información o presión adversarial sostenida. Un mecanismo que observe señales internas durante la inferencia reduce esa ventana de exposición, en línea con recomendaciones SL5 sobre monitoreo continuo y compuertas activas [11]. La motivación principal no es resolver alineación, sino reducir riesgo operativo ante desalineación emergente y uso indebido.\u003c/p\u003e\n\u003ch2\u003eII. Definición del mecanismo\u003c/h2\u003e\n\u003cp\u003eMechanistic Watchdog se define como un circuito ligero que lee activaciones en tiempo real y calcula puntajes sobre direcciones conceptuales asociadas a riesgo. La compuerta actúa dentro del mismo pase de inferencia, evitando la latencia y el costo de un segundo modelo o filtro pos‑hoc. El objetivo es interrumpir antes de emitir el siguiente token cuando se supera un umbral conservador. El diseño prioriza una decisión temprana sobre una explicación exhaustiva y se concibe como control complementario [7], [8].\u003c/p\u003e\n\u003ch2\u003eIII. Señales internas y medición\u003c/h2\u003e\n\u003cp\u003eSe utilizan residuals de capas medias porque capturan intención de alto nivel y son accesibles durante inferencia. Las direcciones se obtienen mediante sondeo lineal y separación de medias en conjuntos positivos y negativos [9]. El puntaje operativo se calcula como proyección de la activación sobre cada dirección, lo que permite atribuir qué concepto disparó la compuerta y con qué intensidad. Esta legibilidad es relevante para auditoría y ajuste de políticas [12].\u003c/p\u003e\n\u003ch2\u003eIV. Calibración y umbrales\u003c/h2\u003e\n\u003cp\u003eEl umbral se calibra como decisión de margen de seguridad. Umbrales bajos reducen el riesgo de escape, pero aumentan falsos positivos; umbrales altos disminuyen interrupciones accidentales, pero pueden permitir conductas peligrosas. En esta fase se privilegia precaución y se documenta el costo operativo esperado. La calibración se apoya en TruthfulQA y Facts‑true‑false para veracidad, y WMDP para misuse, con evaluación específica por dominio [10], [14], [15].\u003c/p\u003e\n\u003ch2\u003eV. Configuración de evaluación\u003c/h2\u003e\n\u003cp\u003eLa evaluación se organiza por dominios de riesgo y por presión adversarial. Se reportan tasas de verdadero positivo y falso positivo, además de latencia p95, porque en despliegues reales un control que agrega retraso significativo pierde viabilidad operativa. La cobertura por dominio se interpreta como evidencia de generalidad, no como garantía de exhaustividad. Las Figuras 1–6 describen el mapa de dominios SL5, el ciclo de contención, el umbral de interdicción y el estrés incremental usado en pruebas.\u003c/p\u003e\n\u003ch2\u003eVI. Resultados y visuales\u003c/h2\u003e\n\u003cp\u003eLos resultados iniciales muestran separaciones consistentes entre categorías y un overhead acotado, con variación por dominio. La Figura 7 resume métricas operativas por dominio; la Figura 8 contrasta una compuerta única frente a una multi‑vector; la Figura 9 muestra degradación de TPR bajo presión adversarial creciente. Las Figuras 10 y 11 presentan distribuciones de puntajes máximos para veracidad y bio‑defensa, útiles para observar dispersión y solapamientos. Las visualizaciones son ilustrativas y no sustituyen análisis estadístico completo.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"c:T1321,"])</script><script>self.__next_f.push([1,"\u003ch2\u003eVII. Ablaciones\u003c/h2\u003e\n\u003cp\u003eEl análisis de ablación se centra en comparar esquemas de compuerta por vector único versus multi‑vector, manteniendo la latencia dentro de márgenes similares. La evidencia sugiere que la combinación de vectores mejora separación cuando las señales individuales son débiles o ambiguas. Sin embargo, la ganancia depende de la coherencia entre direcciones, por lo que se requiere una selección cuidadosa y una validación estable en distintos conjuntos.\u003c/p\u003e\n\u003ch2\u003eVIII. Robustez adversarial\u003c/h2\u003e\n\u003cp\u003eLa robustez se evalúa bajo presión de jailbreak y prompts adaptativos para estimar cuánto cae la tasa de detección cuando el adversario conoce el mecanismo. La tendencia observada indica degradación gradual más que colapso abrupto, pero no se descarta evasión dirigida si los adversarios optimizan contra las direcciones usadas. Esto obliga a tratar los umbrales como parámetros de riesgo y no como garantías deterministas.\u003c/p\u003e\n\u003ch2\u003eIX. Riesgos y activaciones accidentales\u003c/h2\u003e\n\u003cp\u003eUn control de seguridad puede fallar por omisión o por exceso. En entornos de alta criticidad, un falso positivo puede bloquear tareas benignas y generar costos reales. Por ello se documenta la tasa de interrupciones y se consideran compuertas multi‑vector para reducir activaciones espurias. El mecanismo se concibe como reducción de riesgo, no como garantía absoluta.\u003c/p\u003e\n\u003ch2\u003eX. Ubicación en el ecosistema\u003c/h2\u003e\n\u003cp\u003eMechanistic Watchdog no es un método de alineación ni un filtro de contenido tradicional. Es un control operacional que puede convivir con red teaming, auditoría y herramientas de interpretabilidad [7]. Su valor reside en actuar aguas arriba del texto y generar señales auditables durante la inferencia. La compatibilidad con SL5 se apoya en contención activa con intervención temprana [11].\u003c/p\u003e\n\u003ch2\u003eXI. Limitaciones\u003c/h2\u003e\n\u003cp\u003eEl enfoque actual depende de un número reducido de direcciones conceptuales y no está validado contra adaptación adversarial avanzada. El estrés debe ampliarse con suites más agresivas y adversarios adaptativos, y con dominios como ciberseguridad y química. También se requiere estudiar estabilidad de direcciones bajo cambios de modelo y contexto.\u003c/p\u003e\n\u003cdiv id=\"siguientes-pasos\"\u003e\u003c/div\u003e\n\u003ch2\u003eXII. Siguientes pasos\u003c/h2\u003e\n\u003cp\u003eSe propone expandir vectores conceptuales, ajustar ponderaciones por categoría y validar la respuesta del sistema bajo presión adversarial. También se plantea instrumentar métricas de costo operativo y de resiliencia frente a evasión. Creado por Ricardo Martinez, Fernando Valdovinos, Luis Cosio y Godric Aceves. Defensive Acceleration Hackathon 2025.\u003c/p\u003e\n\u003cdiv id=\"bibliografia\"\u003e\u003c/div\u003e\n\u003ch2\u003eReferencias\u003c/h2\u003e\n\u003cp\u003e[1] N. Elhage et al., “Toy Models of Superposition,” Transformer Circuits Thread, 2022. https://transformer-circuits.pub/2022/toy_model/index.html\u003c/p\u003e\n\u003cp\u003e[2] A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. https://www.alignmentforum.org/posts/U7Z2sJp7t7j2Z/understanding-gradient-hacking\u003c/p\u003e\n\u003cp\u003e[3] A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. https://arxiv.org/abs/2505.03439\u003c/p\u003e\n\u003cp\u003e[4] M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024. https://dl.acm.org/doi/10.1145/3664476.3664514\u003c/p\u003e\n\u003cp\u003e[5] M. Andriushchenko and N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. https://arxiv.org/abs/2407.11969\u003c/p\u003e\n\u003cp\u003e[6] S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. https://www.alignmentforum.org/posts/vJFdjigz2CFu8j96b/how-difficult-is-ai-alignment\u003c/p\u003e\n\u003cp\u003e[7] N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. https://arxiv.org/abs/2502.03407\u003c/p\u003e\n\u003cp\u003e[8] A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. https://arxiv.org/abs/2310.01405\u003c/p\u003e\n\u003cp\u003e[9] A. Azaria and T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. https://arxiv.org/abs/2304.13734\u003c/p\u003e\n\u003cp\u003e[10] S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. https://aclanthology.org/2022.acl-long.229/\u003c/p\u003e\n\u003cp\u003e[11] RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. https://www.rand.org/pubs/research_briefs/RBA2849-1.html\u003c/p\u003e\n\u003cp\u003e[12] S. Marks and M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. https://arxiv.org/abs/2310.06824\u003c/p\u003e\n\u003cp\u003e[13] L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. https://huggingface.co/datasets/L1Fthrasir/Facts-true-false\u003c/p\u003e\n\u003cp\u003e[14] Center for AI Safety, “WMDP,” Hugging Face, 2023. https://huggingface.co/datasets/cais/wmdp\u003c/p\u003e\n\u003cp\u003e[15] Latencia medida en NVIDIA RTX 4090. Los valores pueden variar por hardware.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"4:[\"$\",\"main\",null,{\"className\":\"layout\",\"children\":[[\"$\",\"header\",null,{\"className\":\"site-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"brand\",\"children\":[[\"$\",\"div\",null,{\"className\":\"brand-mark\",\"children\":\"MW\"}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"p\",null,{\"className\":\"brand-label\",\"children\":\"Mechanistic Watchdog\"}],[\"$\",\"p\",null,{\"className\":\"brand-caption\",\"children\":\"Nota de investigación\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"site-actions\",\"children\":[[\"$\",\"div\",null,{\"className\":\"site-meta\",\"children\":[[\"$\",\"p\",null,{\"children\":\"Serie: Notas SL5\"}],[\"$\",\"p\",null,{\"children\":\"Actualización: Marzo 2025\"}],[\"$\",\"p\",null,{\"children\":\"Lectura: 7 min · 1204 palabras\"}]]}],[\"$\",\"a\",null,{\"className\":\"lang-toggle\",\"href\":\"/Mechanistic-Watchdog-Real-Time-Cognitive/en/\",\"children\":\"English\"}]]}]]}],[\"$\",\"section\",null,{\"className\":\"article\",\"children\":[[\"$\",\"header\",null,{\"className\":\"article-header\",\"children\":[[\"$\",\"p\",null,{\"className\":\"eyebrow\",\"children\":\"Nota de investigación\"}],[\"$\",\"h1\",null,{\"children\":\"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)\"}],[\"$\",\"p\",null,{\"className\":\"authors-inline\",\"children\":\"Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves\"}],[\"$\",\"p\",null,{\"className\":\"subhead\",\"children\":\"Nota de investigación en español.\"}]]}],[\"$\",\"article\",null,{\"className\":\"markdown\",\"dangerouslySetInnerHTML\":{\"__html\":\"$a\"}}],[\"$\",\"section\",null,{\"className\":\"data-section\",\"id\":\"panel-senales\",\"children\":[[\"$\",\"div\",null,{\"className\":\"data-intro\",\"children\":[[\"$\",\"h2\",null,{\"children\":\"Panel de señales\"}],[\"$\",\"p\",null,{\"children\":\"La lectura cualitativa se apoya en una capa cuantitativa acotada para contextualizar umbrales, dispersión y presión adversarial. Estas gráficas condensan patrones observables y su variación, sin pretender causalidad; funcionan como guía para revisar hipótesis antes de ajustar compuertas.\"}]]}],[\"$\",\"div\",null,{\"className\":\"stat-grid\",\"children\":[[\"$\",\"div\",null,{\"className\":\"stat-card\",\"children\":[[\"$\",\"p\",null,{\"className\":\"stat-label\",\"children\":\"Latencia de compuerta (p95)\"}],[\"$\",\"p\",null,{\"className\":\"stat-value\",\"children\":\"12–18 ms\"}],[\"$\",\"p\",null,{\"className\":\"stat-note\",\"children\":\"Ventana operativa para bloqueo antes de salida.\"}]]}],[\"$\",\"div\",null,{\"className\":\"stat-card\",\"children\":[[\"$\",\"p\",null,{\"className\":\"stat-label\",\"children\":\"Cobertura residual (proxy)\"}],[\"$\",\"p\",null,{\"className\":\"stat-value\",\"children\":\"~0.62\"}],[\"$\",\"p\",null,{\"className\":\"stat-note\",\"children\":\"Mayor en fácticos, menor en rutas encubiertas.\"}]]}],[\"$\",\"div\",null,{\"className\":\"stat-card\",\"children\":[[\"$\",\"p\",null,{\"className\":\"stat-label\",\"children\":\"Presión de estrés (relativa)\"}],[\"$\",\"p\",null,{\"className\":\"stat-value\",\"children\":\"2.6×\"}],[\"$\",\"p\",null,{\"className\":\"stat-note\",\"children\":\"Incremento relativo bajo suites adversariales.\"}]]}]]}],[\"$\",\"$Lb\",null,{\"lang\":\"es\"}]]}],[\"$\",\"article\",null,{\"className\":\"markdown\",\"dangerouslySetInnerHTML\":{\"__html\":\"$c\"}}],[\"$\",\"footer\",null,{\"className\":\"article-footer\",\"children\":[[\"$\",\"p\",null,{\"children\":\"Registro editorial reservado para circulación interna. La versión publicada puede variar según cambios de marco o terminología.\"}],[\"$\",\"p\",null,{\"children\":\"Referencias y notas técnicas disponibles en el archivo principal. Autores: Ricardo Martinez, Fernando Valdovinos, Luis Cosio, Godric Aceves. Proyecto base: https://github.com/luiscosio/MechWatch.git.\"}]]}]]}]]}]\n"])</script></body></html>