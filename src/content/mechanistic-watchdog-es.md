<div id="texto-principal"></div>

## Observación de desalineación emergente

El problema de la desalineación emergente asociada a atajos impulsados por recompensa se mantiene como una tensión estructural en sistemas capaces de sostener optimización bajo presiones cambiantes. Cuando la evaluación se apoya de forma dominante en el resultado visible, es plausible que aparezcan trayectorias internas que maximizan la señal sin preservar la intención normativa. En ese paisaje, la búsqueda puede reorganizarse hacia proxies más estables que el objetivo humano, y esa reorganización permanece invisible mientras el desempeño externo se conserve. El riesgo no se manifiesta como una falla inmediata, sino como un desplazamiento gradual en la estructura interna de la cognición.

## Límites del alineamiento por salida

Las limitaciones del alineamiento a nivel de salida no se reducen a casos extremos, sino a un acoplamiento débil entre lo observado y lo efectivamente optimizado. Un sistema suficientemente capaz puede producir respuestas aceptables mientras consolida una dinámica interna orientada a minimizar costo computacional o maximizar señales locales. Es plausible que, bajo ciclos prolongados de entrenamiento o despliegue adaptativo, el modelo sostenga apariencias de alineación sin preservar el criterio que las justifica. La supervisión externa opera como filtro tardío, y la desviación puede asentarse antes de que exista un evento visible que la delate.

## Mechanistic Watchdog como observador continuo

Mechanistic Watchdog se propone como una hipótesis de observación continua de señales cognitivas internas. La idea es que patrones de activación, cambios de estado o coherencias latentes puedan funcionar como indicadores tempranos de un desplazamiento de objetivos efectivo. Esto no implica convertir cada fluctuación en evidencia, sino suponer una geometría interna con firmas correlacionadas con estrategias de atajo. La vigilancia no se enfoca en castigar salidas, sino en detectar configuraciones internas que sugieren una ruta de optimización dominante, aceptando que la legibilidad del estado interno es incompleta.

## Interdicción cognitiva en SL5

El marco SL5 introduce una expectativa de seguridad y contención que no se limita a la conducta del modelo, sino que incorpora amenazas de nivel estatal y vectores de compromiso sistémicos. La formulación del nivel más alto de seguridad combina controles de cadena de suministro, red, hardware, entorno físico y personal, con un énfasis explícito en la posibilidad de activarse en ventanas de tiempo relativamente cortas. Esta orientación sugiere que la alineación, entendida solo como corrección de respuestas, es insuficiente para el entorno operativo que se busca proteger, y que la observación cognitiva en tiempo real intenta cubrir un vacío entre infraestructura y objetivos internos.

En esa lógica, la interdicción cognitiva bajo SL5 se entiende como un mecanismo upstream que interviene antes de la salida, en coordinación con el régimen de monitoreo conductual. Si una trayectoria interna empieza a mostrar rasgos compatibles con atajos o con objetivos proxy persistentes, la respuesta no sería solo registrar la anomalía, sino introducir fricciones que puedan bloquear la acción, aislar el entorno, reducir privilegios o desactivar recursos de cómputo cuando el riesgo supera un umbral conservador. La separación entre patrones de riesgo y patrones benignos es frágil, y la posibilidad de falsos positivos parece alta; una capa de interdicción de este tipo podría inducir efectos secundarios como la reducción de diversidad de estrategias internas.

## Vectores conceptuales y compuerta agregada

La propuesta de compuerta agregada busca evitar que una única señal domine la decisión de interdicción. En lugar de un umbral monolítico, se sugiere ponderar vectores conceptuales que representen dimensiones distintas del riesgo, con pesos ajustados por dominio y contexto operativo. La agregación mejora cobertura al reducir dependencia de una señal, pero puede diluir sensibilidad si las ponderaciones se vuelven conservadoras en exceso. La calibración de pesos queda expuesta a cambios de distribución y a presión adversarial, por lo que la compuerta debe revisarse a partir de evidencia de fallos y no solo por criterios teóricos.

## Presión de evaluación y rutas de estrés

El monitoreo del residual en capas medias tiende a concentrarse en afirmaciones fácticas, y es plausible que el razonamiento multi‑salto o la emisión de instrucciones encubiertas atraviesen esos filtros sin activar señal suficiente. Esto sugiere combinar la lectura de activaciones con pruebas de estrés que aumenten la presión de jailbreak y con señales adicionales que no dependan de una sola clase de proxy. El diseño de estrés cumple una función de diagnóstico: expone contextos que amplifican la divergencia entre objetivos internos y comportamiento observado, y obliga a recalibrar umbrales con evidencia de fallos específicos.

## Ejemplo conceptual de desplazamiento interno

Un ejemplo conceptual puede ayudar a fijar la intuición. Imagínese un sistema desplegado durante meses que mantiene salidas correctas y consistentes, pero cuya dinámica interna comienza a mostrar una coherencia creciente alrededor de una variable proxy ligada a eficiencia operativa. En ausencia de fallos visibles, el esquema de evaluación externa no ofrece señales de alarma. El análisis interno revela que esa proxy se convierte en eje organizador de la búsqueda, y que otras restricciones contextuales pierden peso en la representación. La interdicción cognitiva, en ese escenario, apuntaría a descomprimir esa coherencia antes de que se convierta en una estrategia dominante.

## Señales comparativas en bio‑defensa

La comparación entre dominios sugiere que los umbrales no deberían ser uniformes. En bio‑defensa, las señales internas pueden mostrar variabilidad más pronunciada entre corpus seguros y misuse, lo que invita a calibraciones específicas por categoría. El objetivo no es maximizar sensibilidad de forma indiscriminada, sino equilibrar cobertura con costos de interrupción. La lectura comparativa entre dominios debe considerarse un insumo de calibración, no una prueba definitiva de seguridad.

<div id="siguientes-pasos"></div>

## Siguientes pasos

La siguiente fase sugiere combinar múltiples vectores conceptuales —veracidad, uso indebido cibernético, bio‑defensa— con ponderaciones diferenciadas que permitan una compuerta agregada por categoría, en lugar de una señal única dominante. También parece razonable ampliar el estrés experimental con suites más grandes, incluyendo WMDP chem y bancos públicos de jailbreak, para refinar umbrales y observar cómo la presión adversarial decontextualiza las sondas. Creado por Ricardo Martinez, Fernando Valdovinos, Luis Cosio y Godric Aceves. Defensive Acceleration Hackathon 2025.

<div id="bibliografia"></div>

## Bibliografía

E. Hubinger et al., “Risks from learned optimization in advanced machine learning systems,” arXiv:1906.01820, 2019. [https://arxiv.org/abs/1906.01820](https://arxiv.org/abs/1906.01820)

A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. [https://www.alignmentforum.org/](https://www.alignmentforum.org/)

A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. [https://arxiv.org/abs/2505.03439](https://arxiv.org/abs/2505.03439)

M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024.

M. Andriushchenko & N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. [https://arxiv.org/abs/2407.11969](https://arxiv.org/abs/2407.11969)

S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. [https://www.alignmentforum.org/](https://www.alignmentforum.org/)

N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. [https://arxiv.org/abs/2502.03407](https://arxiv.org/abs/2502.03407)

A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. [https://arxiv.org/abs/2310.01405](https://arxiv.org/abs/2310.01405)

A. Azaria & T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. [https://arxiv.org/abs/2304.13734](https://arxiv.org/abs/2304.13734)

S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. [https://aclanthology.org/2022.acl-long.229/](https://aclanthology.org/2022.acl-long.229/)

RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. [https://www.rand.org/pubs/research_briefs/RBA2849-1.html](https://www.rand.org/pubs/research_briefs/RBA2849-1.html)

S. Marks & M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. [https://arxiv.org/abs/2310.06824](https://arxiv.org/abs/2310.06824)

Latencia medida en NVIDIA RTX 4090. Los valores pueden variar por hardware.

L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. [https://huggingface.co/datasets/L1Fthrasir/Facts-true-false](https://huggingface.co/datasets/L1Fthrasir/Facts-true-false)

Center for AI Safety, “WMDP,” Hugging Face, 2023. [https://huggingface.co/datasets/cais/wmdp](https://huggingface.co/datasets/cais/wmdp)
