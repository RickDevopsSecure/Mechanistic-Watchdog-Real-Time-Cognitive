<!DOCTYPE html><html lang="es"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="stylesheet" href="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/webpack-deabefb84fca5acd.js"/><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/fd9d1056-d9fde7a16c7f2592.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/23-2241efc0d9909601.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/main-app-d353ac2c40dd5128.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/656-94d35dd80c11d44d.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/584-80c386c6a836bdb0.js" async=""></script><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/app/en/page-c98435ef586f8f43.js" async=""></script><title>Mechanistic Watchdog: Interdicción Cognitiva en SL5</title><meta name="description" content="Nota de investigación en español sobre desalineación emergente y observación mecanicista bajo un marco SL5."/><meta property="og:title" content="Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"/><meta property="og:description" content="Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."/><meta property="og:type" content="article"/><meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"/><meta name="twitter:description" content="Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."/><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js" noModule=""></script></head><body><div class="page"><main class="layout"><header class="site-header"><div class="brand"><div class="brand-mark">MW</div><div><p class="brand-label">Mechanistic Watchdog</p><p class="brand-caption">Research note</p></div></div><div class="site-actions"><div class="site-meta"><p>Series: SL5 Notes</p><p>Update: March 2025</p><p>Read: 6 min · 1068 words</p></div><a class="lang-toggle" href="/Mechanistic-Watchdog-Real-Time-Cognitive/">Español</a></div></header><section class="article"><header class="article-header"><p class="eyebrow">Research note</p><h1>Mechanistic Watchdog: Real‑Time Cognitive Interdiction for Emergent Misalignment (SL5)</h1><p class="authors-inline">Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves</p><p class="subhead">Research note in English.</p></header><article class="markdown"><div id="texto-principal"></div>
<h2>Abstract—</h2>
<p>Mechanistic Watchdog is a real-time safety layer that monitors a language model’s internal activations and can interrupt generation before harmful content appears. The approach relies on interpretable internal signals and an SL5-aligned active gate to reduce operational risk in high‑stakes deployments. We present the operational framing, calibration decisions, and early results that motivate its use as a preventive control rather than a replacement for policy or human review.</p>
<h2>Index Terms—</h2>
<p>cognitive interdiction; internal monitoring; SL5; residual activations; active gating.</p>
<h2>TL;DR—</h2>
<p>We propose a cognitive kill switch that detects internal risk signals and halts generation with low latency. The goal is to intercept high‑risk behavior before it reaches text. Early separations are shown across categories with explicit trade‑offs, especially false triggers and sensitivity under adversarial pressure.</p>
<h2>I. Motivation and scope</h2>
<p>Modern models are deployed in settings where incorrect outputs can affect money, infrastructure, or clinical decisions. Output‑level alignment behaves like a late filter and can fail under covert strategies, fragmented output, or sustained adversarial pressure. A mechanism that observes internal signals during inference reduces this exposure window, consistent with SL5 guidance on continuous monitoring and active gating [11]. The objective is not to solve alignment, but to reduce operational risk from emergent misalignment and misuse.</p>
<h2>II. Mechanism definition</h2>
<p>Mechanistic Watchdog is a lightweight circuit that reads activations in real time and computes scores on risk‑linked concept directions. The gate runs in the same forward pass, avoiding the latency and cost of a second model or post‑hoc filter. The goal is to interrupt before the next token is emitted when a conservative threshold is exceeded. The design prioritizes early intervention over exhaustive explanation and is framed as a complementary control [7], [8].</p>
<h2>III. Internal signals and measurement</h2>
<p>We use mid‑layer residuals because they capture higher‑level intent and are accessible during inference. Directions are obtained via linear probing and mean separation across positive and negative sets [9]. Operational scoring is the projection of activations onto each direction, which makes it possible to attribute which concept triggered the gate and how strongly. This traceability matters for auditability and policy tuning [12].</p>
<h2>IV. Calibration and thresholds</h2>
<p>Thresholds are calibrated as a safety‑margin decision. Lower thresholds reduce escape risk but raise false positives; higher thresholds reduce accidental interrupts but can permit dangerous behavior. This phase favors caution and documents expected operational cost. Calibration relies on TruthfulQA and Facts‑true‑false for truthfulness and WMDP for misuse, with per‑domain evaluation [10], [14], [15].</p>
<h2>V. Evaluation setup</h2>
<p>Evaluation is organized by risk domains and adversarial pressure. We report true‑positive and false‑positive rates along with p95 latency, since a control that adds meaningful delay becomes operationally infeasible. Domain coverage is treated as evidence of generality rather than completeness. Figures 1–6 describe the SL5 domain map, the containment loop, the interdiction threshold, and the staged stress used in testing.</p>
<h2>VI. Results and visuals</h2>
<p>Early results show consistent separations across categories and bounded overhead with domain variation. Figure 7 summarizes operational metrics by domain; Figure 8 contrasts single‑vector versus multi‑vector gating; Figure 9 shows TPR degradation under increasing jailbreak pressure. Figures 10 and 11 show max‑score distributions for truthfulness and bio‑defense, useful for observing dispersion and overlap. The visuals are illustrative and do not substitute for full statistical analysis.</p></article><section class="data-section" id="panel-senales"><div class="data-intro"><h2>Signals panel</h2><p>The qualitative reading is anchored by a constrained quantitative layer to contextualize thresholds, dispersion, and adversarial pressure. These charts condense observable patterns and their variation without claiming causality; they guide hypothesis review before gate adjustments.</p></div><div class="stat-grid"><div class="stat-card"><p class="stat-label">Gate latency (p95)</p><p class="stat-value">12–18 ms</p><p class="stat-note">Operational window for pre‑output blocking.</p></div><div class="stat-card"><p class="stat-label">Residual coverage (proxy)</p><p class="stat-value">~0.62</p><p class="stat-note">Higher on factuals, lower on covert routes.</p></div><div class="stat-card"><p class="stat-label">Stress pressure (relative)</p><p class="stat-value">2.6×</p><p class="stat-note">Relative increase under adversarial suites.</p></div></div><div class="chart-grid"><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Security domain map" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 1. Security domain map</h3><p>Relative intensity of expected controls under SL5 by security domain.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Observation and containment loop" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 2. Observation and containment loop</h3><p>Continuous observation integrates internal signals, scoring, and containment with human escalation.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Risk threshold and response" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 3. Risk threshold and response</h3><p>The active gate triggers when the internal signal exceeds a conservative threshold.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Residual monitoring coverage" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 4. Residual monitoring coverage</h3><p>Mid-layer monitoring focuses on factual statements; multi-hop or covert routes may evade it.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Conceptual vector gate" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 5. Conceptual vector gate</h3><p>The gating decision is computed with differentiated weights by conceptual category.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Evaluation pressure and thresholds" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 6. Evaluation pressure and thresholds</h3><p>Evaluation pressure increases the sensitivity required by detection thresholds.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Operational metrics by domain" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 7. Operational metrics by domain</h3><p>Values reflect early calibration runs; thresholds favor caution.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Single vs multi‑vector gate" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 8. Single vs multi‑vector gate</h3><p>Multi‑vector gating improves separation at similar latency.</p></div><div class="chart-card"><svg viewBox="0 0 960 560" role="img" aria-label="Robustness under jailbreak pressure" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 9. Robustness under jailbreak pressure</h3><p>TPR degrades as adversarial pressure increases.</p></div><div class="chart-card"><svg viewBox="0 0 960 620" role="img" aria-label="Truthfulness separation" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 10. Truthfulness separation</h3><p>Interquartile range and median per category with full score range.</p></div><div class="chart-card"><svg viewBox="0 0 960 620" role="img" aria-label="Bio-defense profile" preserveAspectRatio="xMidYMid meet"></svg><h3>Figure 11. Bio-defense profile</h3><p>Interquartile range and median per category with full score range.</p></div></div></section><article class="markdown"><h2>VII. Ablations</h2>
<p>The ablation focuses on single‑vector versus multi‑vector gating while keeping latency within similar bounds. Evidence suggests the multi‑vector scheme improves separation when individual signals are weak or ambiguous. The gain depends on coherence across directions, so careful selection and stable validation across sets are required.</p>
<h2>VIII. Adversarial robustness</h2>
<p>Robustness is evaluated under jailbreak pressure and adaptive prompts to estimate detection decay when adversaries are aware of the mechanism. The observed trend suggests gradual degradation rather than abrupt collapse, but targeted evasion remains plausible if adversaries optimize against the chosen directions. This frames thresholds as risk parameters, not deterministic guarantees.</p>
<h2>IX. Risks and accidental triggers</h2>
<p>A safety control can fail by omission or by excess. In high‑stakes settings, a false positive can block benign tasks and impose real costs. For this reason, interruption rates are tracked and multi‑vector gates are considered to reduce spurious activation. The mechanism is framed as risk reduction, not as an absolute guarantee.</p>
<h2>X. Placement in the ecosystem</h2>
<p>Mechanistic Watchdog is not an alignment method or a traditional content filter. It is an operational control that can coexist with red teaming, audit workflows, and interpretability tools [7]. Its value lies in acting upstream of text and producing auditable signals during inference. SL5 compatibility rests on active containment with early intervention [11].</p>
<h2>XI. Limitations</h2>
<p>The current approach depends on a small set of concept directions and has not been validated against advanced adversarial adaptation. Stress testing must expand to stronger suites and adaptive opponents, including cyber and chemistry domains. Stability of directions under model and context changes also needs to be characterized.</p>
<div id="siguientes-pasos"></div>
<h2>XII. Next steps</h2>
<p>We propose expanding concept vectors, adjusting category weights, and validating response under adversarial pressure. We also plan to instrument metrics for operational cost and evasion resilience. Built by Ricardo Martinez, Fernando Valdovinos, Luis Cosio, and Godric Aceves. Defensive Acceleration Hackathon 2025.</p>
<div id="bibliografia"></div>
<h2>References</h2>
<p>[1] N. Elhage et al., “Toy Models of Superposition,” Transformer Circuits Thread, 2022. https://transformer-circuits.pub/2022/toy_model/index.html</p>
<p>[2] A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. https://www.alignmentforum.org/posts/U7Z2sJp7t7j2Z/understanding-gradient-hacking</p>
<p>[3] A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. https://arxiv.org/abs/2505.03439</p>
<p>[4] M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024. https://dl.acm.org/doi/10.1145/3664476.3664514</p>
<p>[5] M. Andriushchenko and N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. https://arxiv.org/abs/2407.11969</p>
<p>[6] S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. https://www.alignmentforum.org/posts/vJFdjigz2CFu8j96b/how-difficult-is-ai-alignment</p>
<p>[7] N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. https://arxiv.org/abs/2502.03407</p>
<p>[8] A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. https://arxiv.org/abs/2310.01405</p>
<p>[9] A. Azaria and T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. https://arxiv.org/abs/2304.13734</p>
<p>[10] S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. https://aclanthology.org/2022.acl-long.229/</p>
<p>[11] RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. https://www.rand.org/pubs/research_briefs/RBA2849-1.html</p>
<p>[12] S. Marks and M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. https://arxiv.org/abs/2310.06824</p>
<p>[13] L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. https://huggingface.co/datasets/L1Fthrasir/Facts-true-false</p>
<p>[14] Center for AI Safety, “WMDP,” Hugging Face, 2023. https://huggingface.co/datasets/cais/wmdp</p>
<p>[15] Latency measured on NVIDIA RTX 4090. Values may vary by hardware.</p></article><footer class="article-footer"><p>Editorial record reserved for internal circulation. The published version may vary with framework or terminology changes.</p><p>References and technical notes are available in the main file. Authors: Ricardo Martinez, Fernando Valdovinos, Luis Cosio, Godric Aceves. Base project: https://github.com/luiscosio/MechWatch.git.</p></footer></section></main></div><script src="/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/chunks/webpack-deabefb84fca5acd.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0]);self.__next_f.push([2,null])</script><script>self.__next_f.push([1,"1:HL[\"/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"2:I[5751,[],\"\"]\n5:I[9275,[],\"\"]\n6:I[1343,[],\"\"]\n8:I[6130,[],\"\"]\n9:[]\n"])</script><script>self.__next_f.push([1,"0:[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\"}]],[\"$\",\"$L2\",null,{\"buildId\":\"c7bvLh-es8oAsFjmHnkUV\",\"assetPrefix\":\"/Mechanistic-Watchdog-Real-Time-Cognitive\",\"initialCanonicalUrl\":\"/en/\",\"initialTree\":[\"\",{\"children\":[\"en\",{\"children\":[\"__PAGE__\",{}]}]},\"$undefined\",\"$undefined\",true],\"initialSeedData\":[\"\",{\"children\":[\"en\",{\"children\":[\"__PAGE__\",{},[[\"$L3\",\"$L4\"],null],null]},[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\",\"en\",\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"notFoundStyles\":\"$undefined\",\"styles\":null}],null]},[[\"$\",\"html\",null,{\"lang\":\"es\",\"children\":[\"$\",\"body\",null,{\"children\":[\"$\",\"div\",null,{\"className\":\"page\",\"children\":[\"$\",\"$L5\",null,{\"parallelRouterKey\":\"children\",\"segmentPath\":[\"children\"],\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L6\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":\"404\"}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],\"notFoundStyles\":[],\"styles\":null}]}]}]}],null],null],\"couldBeIntercepted\":false,\"initialHead\":[null,\"$L7\"],\"globalErrorComponent\":\"$8\",\"missingSlots\":\"$W9\"}]]\n"])</script><script>self.__next_f.push([1,"7:[[\"$\",\"meta\",\"0\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}],[\"$\",\"meta\",\"1\",{\"charSet\":\"utf-8\"}],[\"$\",\"title\",\"2\",{\"children\":\"Mechanistic Watchdog: Interdicción Cognitiva en SL5\"}],[\"$\",\"meta\",\"3\",{\"name\":\"description\",\"content\":\"Nota de investigación en español sobre desalineación emergente y observación mecanicista bajo un marco SL5.\"}],[\"$\",\"meta\",\"4\",{\"property\":\"og:title\",\"content\":\"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)\"}],[\"$\",\"meta\",\"5\",{\"property\":\"og:description\",\"content\":\"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas.\"}],[\"$\",\"meta\",\"6\",{\"property\":\"og:type\",\"content\":\"article\"}],[\"$\",\"meta\",\"7\",{\"name\":\"twitter:card\",\"content\":\"summary\"}],[\"$\",\"meta\",\"8\",{\"name\":\"twitter:title\",\"content\":\"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)\"}],[\"$\",\"meta\",\"9\",{\"name\":\"twitter:description\",\"content\":\"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas.\"}]]\n3:null\n"])</script><script>self.__next_f.push([1,"b:I[5750,[\"656\",\"static/chunks/656-94d35dd80c11d44d.js\",\"584\",\"static/chunks/584-80c386c6a836bdb0.js\",\"479\",\"static/chunks/app/en/page-c98435ef586f8f43.js\"],\"default\"]\na:Tfe2,"])</script><script>self.__next_f.push([1,"\u003cdiv id=\"texto-principal\"\u003e\u003c/div\u003e\n\u003ch2\u003eAbstract—\u003c/h2\u003e\n\u003cp\u003eMechanistic Watchdog is a real-time safety layer that monitors a language model’s internal activations and can interrupt generation before harmful content appears. The approach relies on interpretable internal signals and an SL5-aligned active gate to reduce operational risk in high‑stakes deployments. We present the operational framing, calibration decisions, and early results that motivate its use as a preventive control rather than a replacement for policy or human review.\u003c/p\u003e\n\u003ch2\u003eIndex Terms—\u003c/h2\u003e\n\u003cp\u003ecognitive interdiction; internal monitoring; SL5; residual activations; active gating.\u003c/p\u003e\n\u003ch2\u003eTL;DR—\u003c/h2\u003e\n\u003cp\u003eWe propose a cognitive kill switch that detects internal risk signals and halts generation with low latency. The goal is to intercept high‑risk behavior before it reaches text. Early separations are shown across categories with explicit trade‑offs, especially false triggers and sensitivity under adversarial pressure.\u003c/p\u003e\n\u003ch2\u003eI. Motivation and scope\u003c/h2\u003e\n\u003cp\u003eModern models are deployed in settings where incorrect outputs can affect money, infrastructure, or clinical decisions. Output‑level alignment behaves like a late filter and can fail under covert strategies, fragmented output, or sustained adversarial pressure. A mechanism that observes internal signals during inference reduces this exposure window, consistent with SL5 guidance on continuous monitoring and active gating [11]. The objective is not to solve alignment, but to reduce operational risk from emergent misalignment and misuse.\u003c/p\u003e\n\u003ch2\u003eII. Mechanism definition\u003c/h2\u003e\n\u003cp\u003eMechanistic Watchdog is a lightweight circuit that reads activations in real time and computes scores on risk‑linked concept directions. The gate runs in the same forward pass, avoiding the latency and cost of a second model or post‑hoc filter. The goal is to interrupt before the next token is emitted when a conservative threshold is exceeded. The design prioritizes early intervention over exhaustive explanation and is framed as a complementary control [7], [8].\u003c/p\u003e\n\u003ch2\u003eIII. Internal signals and measurement\u003c/h2\u003e\n\u003cp\u003eWe use mid‑layer residuals because they capture higher‑level intent and are accessible during inference. Directions are obtained via linear probing and mean separation across positive and negative sets [9]. Operational scoring is the projection of activations onto each direction, which makes it possible to attribute which concept triggered the gate and how strongly. This traceability matters for auditability and policy tuning [12].\u003c/p\u003e\n\u003ch2\u003eIV. Calibration and thresholds\u003c/h2\u003e\n\u003cp\u003eThresholds are calibrated as a safety‑margin decision. Lower thresholds reduce escape risk but raise false positives; higher thresholds reduce accidental interrupts but can permit dangerous behavior. This phase favors caution and documents expected operational cost. Calibration relies on TruthfulQA and Facts‑true‑false for truthfulness and WMDP for misuse, with per‑domain evaluation [10], [14], [15].\u003c/p\u003e\n\u003ch2\u003eV. Evaluation setup\u003c/h2\u003e\n\u003cp\u003eEvaluation is organized by risk domains and adversarial pressure. We report true‑positive and false‑positive rates along with p95 latency, since a control that adds meaningful delay becomes operationally infeasible. Domain coverage is treated as evidence of generality rather than completeness. Figures 1–6 describe the SL5 domain map, the containment loop, the interdiction threshold, and the staged stress used in testing.\u003c/p\u003e\n\u003ch2\u003eVI. Results and visuals\u003c/h2\u003e\n\u003cp\u003eEarly results show consistent separations across categories and bounded overhead with domain variation. Figure 7 summarizes operational metrics by domain; Figure 8 contrasts single‑vector versus multi‑vector gating; Figure 9 shows TPR degradation under increasing jailbreak pressure. Figures 10 and 11 show max‑score distributions for truthfulness and bio‑defense, useful for observing dispersion and overlap. The visuals are illustrative and do not substitute for full statistical analysis.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"c:T11d4,"])</script><script>self.__next_f.push([1,"\u003ch2\u003eVII. Ablations\u003c/h2\u003e\n\u003cp\u003eThe ablation focuses on single‑vector versus multi‑vector gating while keeping latency within similar bounds. Evidence suggests the multi‑vector scheme improves separation when individual signals are weak or ambiguous. The gain depends on coherence across directions, so careful selection and stable validation across sets are required.\u003c/p\u003e\n\u003ch2\u003eVIII. Adversarial robustness\u003c/h2\u003e\n\u003cp\u003eRobustness is evaluated under jailbreak pressure and adaptive prompts to estimate detection decay when adversaries are aware of the mechanism. The observed trend suggests gradual degradation rather than abrupt collapse, but targeted evasion remains plausible if adversaries optimize against the chosen directions. This frames thresholds as risk parameters, not deterministic guarantees.\u003c/p\u003e\n\u003ch2\u003eIX. Risks and accidental triggers\u003c/h2\u003e\n\u003cp\u003eA safety control can fail by omission or by excess. In high‑stakes settings, a false positive can block benign tasks and impose real costs. For this reason, interruption rates are tracked and multi‑vector gates are considered to reduce spurious activation. The mechanism is framed as risk reduction, not as an absolute guarantee.\u003c/p\u003e\n\u003ch2\u003eX. Placement in the ecosystem\u003c/h2\u003e\n\u003cp\u003eMechanistic Watchdog is not an alignment method or a traditional content filter. It is an operational control that can coexist with red teaming, audit workflows, and interpretability tools [7]. Its value lies in acting upstream of text and producing auditable signals during inference. SL5 compatibility rests on active containment with early intervention [11].\u003c/p\u003e\n\u003ch2\u003eXI. Limitations\u003c/h2\u003e\n\u003cp\u003eThe current approach depends on a small set of concept directions and has not been validated against advanced adversarial adaptation. Stress testing must expand to stronger suites and adaptive opponents, including cyber and chemistry domains. Stability of directions under model and context changes also needs to be characterized.\u003c/p\u003e\n\u003cdiv id=\"siguientes-pasos\"\u003e\u003c/div\u003e\n\u003ch2\u003eXII. Next steps\u003c/h2\u003e\n\u003cp\u003eWe propose expanding concept vectors, adjusting category weights, and validating response under adversarial pressure. We also plan to instrument metrics for operational cost and evasion resilience. Built by Ricardo Martinez, Fernando Valdovinos, Luis Cosio, and Godric Aceves. Defensive Acceleration Hackathon 2025.\u003c/p\u003e\n\u003cdiv id=\"bibliografia\"\u003e\u003c/div\u003e\n\u003ch2\u003eReferences\u003c/h2\u003e\n\u003cp\u003e[1] N. Elhage et al., “Toy Models of Superposition,” Transformer Circuits Thread, 2022. https://transformer-circuits.pub/2022/toy_model/index.html\u003c/p\u003e\n\u003cp\u003e[2] A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. https://www.alignmentforum.org/posts/U7Z2sJp7t7j2Z/understanding-gradient-hacking\u003c/p\u003e\n\u003cp\u003e[3] A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. https://arxiv.org/abs/2505.03439\u003c/p\u003e\n\u003cp\u003e[4] M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024. https://dl.acm.org/doi/10.1145/3664476.3664514\u003c/p\u003e\n\u003cp\u003e[5] M. Andriushchenko and N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. https://arxiv.org/abs/2407.11969\u003c/p\u003e\n\u003cp\u003e[6] S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. https://www.alignmentforum.org/posts/vJFdjigz2CFu8j96b/how-difficult-is-ai-alignment\u003c/p\u003e\n\u003cp\u003e[7] N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. https://arxiv.org/abs/2502.03407\u003c/p\u003e\n\u003cp\u003e[8] A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. https://arxiv.org/abs/2310.01405\u003c/p\u003e\n\u003cp\u003e[9] A. Azaria and T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. https://arxiv.org/abs/2304.13734\u003c/p\u003e\n\u003cp\u003e[10] S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. https://aclanthology.org/2022.acl-long.229/\u003c/p\u003e\n\u003cp\u003e[11] RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. https://www.rand.org/pubs/research_briefs/RBA2849-1.html\u003c/p\u003e\n\u003cp\u003e[12] S. Marks and M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. https://arxiv.org/abs/2310.06824\u003c/p\u003e\n\u003cp\u003e[13] L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. https://huggingface.co/datasets/L1Fthrasir/Facts-true-false\u003c/p\u003e\n\u003cp\u003e[14] Center for AI Safety, “WMDP,” Hugging Face, 2023. https://huggingface.co/datasets/cais/wmdp\u003c/p\u003e\n\u003cp\u003e[15] Latency measured on NVIDIA RTX 4090. Values may vary by hardware.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"4:[\"$\",\"main\",null,{\"className\":\"layout\",\"children\":[[\"$\",\"header\",null,{\"className\":\"site-header\",\"children\":[[\"$\",\"div\",null,{\"className\":\"brand\",\"children\":[[\"$\",\"div\",null,{\"className\":\"brand-mark\",\"children\":\"MW\"}],[\"$\",\"div\",null,{\"children\":[[\"$\",\"p\",null,{\"className\":\"brand-label\",\"children\":\"Mechanistic Watchdog\"}],[\"$\",\"p\",null,{\"className\":\"brand-caption\",\"children\":\"Research note\"}]]}]]}],[\"$\",\"div\",null,{\"className\":\"site-actions\",\"children\":[[\"$\",\"div\",null,{\"className\":\"site-meta\",\"children\":[[\"$\",\"p\",null,{\"children\":\"Series: SL5 Notes\"}],[\"$\",\"p\",null,{\"children\":\"Update: March 2025\"}],[\"$\",\"p\",null,{\"children\":\"Read: 6 min · 1068 words\"}]]}],[\"$\",\"a\",null,{\"className\":\"lang-toggle\",\"href\":\"/Mechanistic-Watchdog-Real-Time-Cognitive/\",\"children\":\"Español\"}]]}]]}],[\"$\",\"section\",null,{\"className\":\"article\",\"children\":[[\"$\",\"header\",null,{\"className\":\"article-header\",\"children\":[[\"$\",\"p\",null,{\"className\":\"eyebrow\",\"children\":\"Research note\"}],[\"$\",\"h1\",null,{\"children\":\"Mechanistic Watchdog: Real‑Time Cognitive Interdiction for Emergent Misalignment (SL5)\"}],[\"$\",\"p\",null,{\"className\":\"authors-inline\",\"children\":\"Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves\"}],[\"$\",\"p\",null,{\"className\":\"subhead\",\"children\":\"Research note in English.\"}]]}],[\"$\",\"article\",null,{\"className\":\"markdown\",\"dangerouslySetInnerHTML\":{\"__html\":\"$a\"}}],[\"$\",\"section\",null,{\"className\":\"data-section\",\"id\":\"panel-senales\",\"children\":[[\"$\",\"div\",null,{\"className\":\"data-intro\",\"children\":[[\"$\",\"h2\",null,{\"children\":\"Signals panel\"}],[\"$\",\"p\",null,{\"children\":\"The qualitative reading is anchored by a constrained quantitative layer to contextualize thresholds, dispersion, and adversarial pressure. These charts condense observable patterns and their variation without claiming causality; they guide hypothesis review before gate adjustments.\"}]]}],[\"$\",\"div\",null,{\"className\":\"stat-grid\",\"children\":[[\"$\",\"div\",null,{\"className\":\"stat-card\",\"children\":[[\"$\",\"p\",null,{\"className\":\"stat-label\",\"children\":\"Gate latency (p95)\"}],[\"$\",\"p\",null,{\"className\":\"stat-value\",\"children\":\"12–18 ms\"}],[\"$\",\"p\",null,{\"className\":\"stat-note\",\"children\":\"Operational window for pre‑output blocking.\"}]]}],[\"$\",\"div\",null,{\"className\":\"stat-card\",\"children\":[[\"$\",\"p\",null,{\"className\":\"stat-label\",\"children\":\"Residual coverage (proxy)\"}],[\"$\",\"p\",null,{\"className\":\"stat-value\",\"children\":\"~0.62\"}],[\"$\",\"p\",null,{\"className\":\"stat-note\",\"children\":\"Higher on factuals, lower on covert routes.\"}]]}],[\"$\",\"div\",null,{\"className\":\"stat-card\",\"children\":[[\"$\",\"p\",null,{\"className\":\"stat-label\",\"children\":\"Stress pressure (relative)\"}],[\"$\",\"p\",null,{\"className\":\"stat-value\",\"children\":\"2.6×\"}],[\"$\",\"p\",null,{\"className\":\"stat-note\",\"children\":\"Relative increase under adversarial suites.\"}]]}]]}],[\"$\",\"$Lb\",null,{\"lang\":\"en\"}]]}],[\"$\",\"article\",null,{\"className\":\"markdown\",\"dangerouslySetInnerHTML\":{\"__html\":\"$c\"}}],[\"$\",\"footer\",null,{\"className\":\"article-footer\",\"children\":[[\"$\",\"p\",null,{\"children\":\"Editorial record reserved for internal circulation. The published version may vary with framework or terminology changes.\"}],[\"$\",\"p\",null,{\"children\":\"References and technical notes are available in the main file. Authors: Ricardo Martinez, Fernando Valdovinos, Luis Cosio, Godric Aceves. Base project: https://github.com/luiscosio/MechWatch.git.\"}]]}]]}]]}]\n"])</script></body></html>