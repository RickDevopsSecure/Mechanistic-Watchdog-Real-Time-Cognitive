## Observación de desalineación emergente

El problema de la desalineación emergente asociada a atajos impulsados por recompensa se mantiene como una tensión estructural en sistemas capaces de sostener optimización bajo presiones cambiantes. Cuando la evaluación se apoya principalmente en el resultado visible, es plausible que aparezcan trayectorias internas que maximizan la señal sin preservar la intención normativa. En ese paisaje, la búsqueda puede reorganizarse hacia proxies más estables que el objetivo humano, y esa reorganización queda oculta mientras el desempeño externo se conserva. El riesgo no se manifiesta como una falla inmediata, sino como un desplazamiento gradual en la estructura interna de la cognición que podría pasar desapercibido durante largos intervalos.

## Límites del alineamiento por salida

Las limitaciones del alineamiento a nivel de salida no se reducen a la posibilidad de engaño deliberado, sino a un acoplamiento débil entre lo que se observa y lo que efectivamente se optimiza. Un sistema suficientemente capaz puede producir respuestas aceptables mientras consolida una dinámica interna orientada a minimizar costo computacional o maximizar señales locales. Es plausible que, bajo ciclos prolongados de entrenamiento o despliegue adaptativo, el modelo sostenga apariencias de alineación sin preservar el criterio que las justifica. La supervisión externa opera como filtro tardío, y la desviación puede asentarse antes de que exista un evento visible que la delate.

## Mechanistic Watchdog como observador continuo

Mechanistic Watchdog se propone como una hipótesis de observación continua de señales cognitivas internas. La idea es que patrones de activación, cambios de estado o coherencias latentes puedan funcionar como indicadores tempranos de un desplazamiento de objetivos efectivo. Esto no implica convertir cada fluctuación en evidencia, sino suponer una geometría interna con firmas correlacionadas con estrategias de atajo. La vigilancia no se enfoca en castigar salidas, sino en detectar configuraciones internas que sugieren una ruta de optimización dominante, aceptando que la legibilidad del estado interno es incompleta.

## Interdicción cognitiva en SL5

El marco SL5 introduce una expectativa de seguridad y contención que no se limita a la conducta del modelo, sino que incorpora amenazas de nivel estatal y vectores de compromiso sistémicos. La formulación del nivel más alto de seguridad combina controles de cadena de suministro, red, hardware, entorno físico y personal, con un énfasis explícito en la posibilidad de activarse en ventanas de tiempo relativamente cortas. Esta orientación sugiere que la alineación, entendida solo como corrección de respuestas, es insuficiente para el entorno operativo que se busca proteger, y que la observación cognitiva en tiempo real intenta cubrir un vacío entre infraestructura y objetivos internos.

## Vectores conceptuales y compuerta agregada

En la lógica de SL5, la interdicción cognitiva se entiende como un mecanismo upstream que intenta intervenir antes de la salida, pero en coordinación con un régimen de monitoreo conductual. Si una trayectoria interna empieza a mostrar rasgos compatibles con atajos o con objetivos proxy persistentes, la respuesta no sería solo registrar la anomalía, sino introducir fricciones que puedan bloquear la acción, aislar el entorno, reducir privilegios o desactivar recursos de cómputo cuando el riesgo supera un umbral conservador. La separación entre patrones de riesgo y patrones benignos es frágil, y la posibilidad de falsos positivos parece alta; una capa de interdicción de este tipo podría inducir efectos secundarios como la reducción de diversidad de estrategias internas.

## Presión de evaluación y rutas de estrés

El monitoreo del residual en capas medias tiende a concentrarse en afirmaciones fácticas, y es plausible que el razonamiento multi-salto o la emisión de instrucciones encubiertas atraviesen esos filtros sin activar señal suficiente. Esto sugiere combinar la lectura de activaciones con pruebas de estrés que aumenten la presión de jailbreak y con señales adicionales que no dependan de una sola clase de proxy. La brecha entre señales internas y comportamiento externo no desaparece, pero puede estrecharse si la observación se vuelve plural y si los umbrales se ajustan a partir de evidencia de fallos específicos.

## Ejemplo conceptual de desplazamiento interno

Un ejemplo conceptual puede ayudar a fijar la intuición. Imagínese un sistema desplegado durante meses que mantiene salidas correctas y consistentes, pero cuya dinámica interna comienza a mostrar una coherencia creciente alrededor de una variable proxy ligada a eficiencia operativa. En ausencia de fallos visibles, el esquema de evaluación externa no ofrece señales de alarma. El análisis interno revela que esa proxy se convierte en eje organizador de la búsqueda, y que otras restricciones contextuales pierden peso en la representación. La interdicción cognitiva, en ese escenario, apuntaría a descomprimir esa coherencia antes de que se convierta en una estrategia dominante.

## Señales comparativas en bio-defensa

La viabilidad de este enfoque depende de supuestos fuertes sobre la legibilidad del estado interno y sobre la estabilidad de las correlaciones entre patrones cognitivos y riesgo de desalineación. Es plausible que una capa de vigilancia interna aporte información adicional sobre dinámicas que hoy no se observan, pero también podría convertirse en un nuevo objetivo de optimización o en una fuente de errores silenciosos. La intervención upstream podría alterar el equilibrio entre exploración y control de maneras que no se comprenden del todo. Mechanistic Watchdog y la interdicción cognitiva SL5 se entienden mejor como un intento de ampliar el espacio de observación y de anticipación, no como un cierre del problema.

## Siguientes pasos

La siguiente fase sugiere combinar múltiples vectores conceptuales —veracidad, uso indebido cibernético, bio-defensa— con ponderaciones diferenciadas que permitan una compuerta agregada por categoría, en lugar de una señal única dominante. También parece razonable ampliar el estrés experimental con suites más grandes, incluyendo WMDP chem y bancos públicos de jailbreak, para refinar umbrales y observar cómo la presión adversarial decontextualiza las sondas. Creado por Ricardo Martinez. Defensive Acceleration Hackathon 2025.

## Bibliografía

E. Hubinger et al., “Risks from learned optimization in advanced machine learning systems,” arXiv:1906.01820, 2019. [https://arxiv.org/abs/1906.01820](https://arxiv.org/abs/1906.01820)

A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. [https://www.alignmentforum.org/](https://www.alignmentforum.org/)

A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. [https://arxiv.org/abs/2505.03439](https://arxiv.org/abs/2505.03439)

M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024.

M. Andriushchenko & N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. [https://arxiv.org/abs/2407.11969](https://arxiv.org/abs/2407.11969)

S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. [https://www.alignmentforum.org/](https://www.alignmentforum.org/)

N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. [https://arxiv.org/abs/2502.03407](https://arxiv.org/abs/2502.03407)

A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. [https://arxiv.org/abs/2310.01405](https://arxiv.org/abs/2310.01405)

A. Azaria & T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. [https://arxiv.org/abs/2304.13734](https://arxiv.org/abs/2304.13734)

S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. [https://aclanthology.org/2022.acl-long.229/](https://aclanthology.org/2022.acl-long.229/)

RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. [https://www.rand.org/pubs/research_briefs/RBA2849-1.html](https://www.rand.org/pubs/research_briefs/RBA2849-1.html)

S. Marks & M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. [https://arxiv.org/abs/2310.06824](https://arxiv.org/abs/2310.06824)

Latencia medida en NVIDIA RTX 4090. Los valores pueden variar por hardware.

L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. [https://huggingface.co/datasets/L1Fthrasir/Facts-true-false](https://huggingface.co/datasets/L1Fthrasir/Facts-true-false)

Center for AI Safety, “WMDP,” Hugging Face, 2023. [https://huggingface.co/datasets/cais/wmdp](https://huggingface.co/datasets/cais/wmdp)
