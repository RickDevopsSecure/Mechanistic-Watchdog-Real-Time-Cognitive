3:I[9275,[],""]
4:I[1343,[],""]
0:["u0JWE7dd3Ve2yJjL_0FM9",[[["",{"children":["__PAGE__",{}]},"$undefined","$undefined",true],["",{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},[["$","html",null,{"lang":"es","children":["$","body",null,{"children":["$","div",null,{"className":"page","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"styles":null}]}]}]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L5"]]]]]
5:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Mechanistic Watchdog: Interdicción Cognitiva en SL5"}],["$","meta","3",{"name":"description","content":"Nota de investigación en español sobre desalineación emergente y observación mecanicista bajo un marco SL5."}],["$","meta","4",{"property":"og:title","content":"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"}],["$","meta","5",{"property":"og:description","content":"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."}],["$","meta","6",{"property":"og:type","content":"article"}],["$","meta","7",{"name":"twitter:card","content":"summary"}],["$","meta","8",{"name":"twitter:title","content":"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"}],["$","meta","9",{"name":"twitter:description","content":"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."}]]
1:null
7:I[5750,["656","static/chunks/656-94d35dd80c11d44d.js","584","static/chunks/584-118b482da1b26d3f.js","931","static/chunks/app/page-4a45228d16941149.js"],"default"]
6:Tf3e,<div id="texto-principal"></div>
<h2>Resumen—</h2>
<p>Mechanistic Watchdog es una capa de seguridad en tiempo real que monitorea activaciones internas de un modelo de lenguaje y puede interrumpir la generación antes de que emerja contenido dañino. El enfoque se apoya en señales internas interpretables y en una compuerta activa alineada con SL5 para reducir riesgo en despliegues de alta criticidad. Se presenta una formulación operativa, decisiones de calibración y resultados iniciales que motivan su uso como control preventivo, no como sustituto de política o revisión humana.</p>
<h2>Términos clave—</h2>
<p>interdicción cognitiva; monitoreo interno; SL5; activaciones residuales; compuerta activa.</p>
<h2>TL;DR—</h2>
<p>Se propone un interruptor cognitivo que detecta señales internas de riesgo y detiene la generación con baja latencia. El objetivo es interceptar conductas de alto riesgo antes de que aparezcan en texto. Se muestran separaciones tempranas entre categorías y trade‑offs relevantes, en particular falsas activaciones y sensibilidad bajo presión adversarial.</p>
<h2>I. Motivación y alcance</h2>
<p>Los modelos actuales se despliegan en entornos donde una salida incorrecta puede impactar dinero, infraestructura o decisiones clínicas. El alineamiento basado en salida opera como filtro tardío y puede fallar ante estrategias encubiertas, fragmentación de información o presión adversarial sostenida. Un mecanismo que observe señales internas durante la inferencia reduce esa ventana de exposición, en línea con recomendaciones SL5 sobre monitoreo continuo y compuertas activas [11]. La motivación principal no es resolver alineación, sino reducir riesgo operativo ante desalineación emergente y uso indebido.</p>
<h2>II. Definición del mecanismo</h2>
<p>Mechanistic Watchdog se define como un circuito ligero que lee activaciones en tiempo real y calcula puntajes sobre direcciones conceptuales asociadas a riesgo. La compuerta actúa dentro del mismo pase de inferencia, evitando la latencia y el costo de un segundo modelo o filtro pos‑hoc. El objetivo es interrumpir antes de emitir el siguiente token cuando se supera un umbral conservador. El diseño prioriza una decisión temprana sobre una explicación exhaustiva y se concibe como control complementario [7], [8].</p>
<h2>III. Señales internas y medición</h2>
<p>Se utilizan residuals de capas medias porque capturan intención de alto nivel y son accesibles durante inferencia. Las direcciones se obtienen mediante sondeo lineal y separación de medias en conjuntos positivos y negativos [9]. El puntaje operativo se calcula como proyección de la activación sobre cada dirección, lo que permite atribuir qué concepto disparó la compuerta y con qué intensidad. Esta legibilidad es relevante para auditoría y ajuste de políticas [12].</p>
<h2>IV. Calibración y umbrales</h2>
<p>El umbral se calibra como decisión de margen de seguridad. Umbrales bajos reducen el riesgo de escape, pero aumentan falsos positivos; umbrales altos disminuyen interrupciones accidentales, pero pueden permitir conductas peligrosas. En esta fase se privilegia precaución y se documenta el costo operativo esperado. La calibración se apoya en TruthfulQA y Facts‑true‑false para veracidad, y WMDP para misuse, con evaluación específica por dominio [10], [14], [15].</p>
<h2>V. Resultados y visuales</h2>
<p>Los resultados iniciales muestran separaciones consistentes entre clases en dos dominios y un overhead de latencia acotado. Las Figuras 1–8 resumen la distribución de controles por dominio, el loop de observación, el umbral de interdicción y la sensibilidad a presión adversarial. Las Figuras 7–8 muestran boxplots de separación por categoría con lectura operacional del umbral. Estas visualizaciones son ilustrativas y no sustituyen análisis estadístico completo.</p>8:Tfcb,<h2>VI. Riesgos y activaciones accidentales</h2>
<p>Un control de seguridad puede fallar por omisión o por exceso. En entornos de alta criticidad, un falso positivo puede bloquear tareas benignas y generar costos reales. Por ello se documenta la tasa de interrupciones y se consideran compuertas multi‑vector para reducir activaciones espurias. El mecanismo se concibe como reducción de riesgo, no como garantía absoluta.</p>
<h2>VII. Ubicación en el ecosistema</h2>
<p>Mechanistic Watchdog no es un método de alineación ni un filtro de contenido tradicional. Es un control operacional que puede convivir con red teaming, auditoría y herramientas de interpretabilidad [7]. Su valor reside en actuar aguas arriba del texto y generar señales auditables durante la inferencia. La compatibilidad con SL5 se apoya en contención activa con intervención temprana [11].</p>
<h2>VIII. Limitaciones y trabajo futuro</h2>
<p>El enfoque actual depende de un número reducido de direcciones conceptuales y no está validado contra adaptación adversarial avanzada. El estrés debe ampliarse con suites más agresivas y adversarios adaptativos, y con dominios como ciberseguridad y química. También se requiere estudiar estabilidad de direcciones bajo cambios de modelo y contexto. El objetivo es mejorar sensibilidad sin aumentar de forma desproporcionada los falsos positivos.</p>
<div id="siguientes-pasos"></div>
<h2>IX. Siguientes pasos</h2>
<p>Se propone expandir vectores conceptuales, ajustar ponderaciones por categoría y validar la respuesta del sistema bajo presión adversarial. También se plantea instrumentar métricas de costo operativo y de resiliencia frente a evasión. Creado por Ricardo Martinez, Fernando Valdovinos, Luis Cosio y Godric Aceves. Defensive Acceleration Hackathon 2025.</p>
<div id="bibliografia"></div>
<h2>Referencias</h2>
<p>[1] N. Elhage et al., “Toy Models of Superposition,” Transformer Circuits Thread, 2022. https://transformer-circuits.pub/2022/toy_model/index.html</p>
<p>[2] A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. https://www.alignmentforum.org/posts/U7Z2sJp7t7j2Z/understanding-gradient-hacking</p>
<p>[3] A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. https://arxiv.org/abs/2505.03439</p>
<p>[4] M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024. https://dl.acm.org/doi/10.1145/3664476.3664514</p>
<p>[5] M. Andriushchenko and N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. https://arxiv.org/abs/2407.11969</p>
<p>[6] S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. https://www.alignmentforum.org/posts/vJFdjigz2CFu8j96b/how-difficult-is-ai-alignment</p>
<p>[7] N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. https://arxiv.org/abs/2502.03407</p>
<p>[8] A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. https://arxiv.org/abs/2310.01405</p>
<p>[9] A. Azaria and T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. https://arxiv.org/abs/2304.13734</p>
<p>[10] S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. https://aclanthology.org/2022.acl-long.229/</p>
<p>[11] RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. https://www.rand.org/pubs/research_briefs/RBA2849-1.html</p>
<p>[12] S. Marks and M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. https://arxiv.org/abs/2310.06824</p>
<p>[13] L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. https://huggingface.co/datasets/L1Fthrasir/Facts-true-false</p>
<p>[14] Center for AI Safety, “WMDP,” Hugging Face, 2023. https://huggingface.co/datasets/cais/wmdp</p>
<p>[15] Latencia medida en NVIDIA RTX 4090. Los valores pueden variar por hardware.</p>2:["$","main",null,{"className":"layout","children":[["$","header",null,{"className":"site-header","children":[["$","div",null,{"className":"brand","children":[["$","div",null,{"className":"brand-mark","children":"MW"}],["$","div",null,{"children":[["$","p",null,{"className":"brand-label","children":"Mechanistic Watchdog"}],["$","p",null,{"className":"brand-caption","children":"Nota de investigación"}]]}]]}],["$","div",null,{"className":"site-actions","children":[["$","div",null,{"className":"site-meta","children":[["$","p",null,{"children":"Serie: Notas SL5"}],["$","p",null,{"children":"Actualización: Marzo 2025"}],["$","p",null,{"children":"Lectura: 6 min · 993 palabras"}]]}],["$","a",null,{"className":"lang-toggle","href":"/Mechanistic-Watchdog-Real-Time-Cognitive/en/","children":"English"}]]}]]}],["$","section",null,{"className":"article","children":[["$","header",null,{"className":"article-header","children":[["$","p",null,{"className":"eyebrow","children":"Nota de investigación"}],["$","h1",null,{"children":"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"}],["$","p",null,{"className":"authors-inline","children":"Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves"}],["$","p",null,{"className":"subhead","children":"Nota de investigación en español."}]]}],["$","article",null,{"className":"markdown","dangerouslySetInnerHTML":{"__html":"$6"}}],["$","section",null,{"className":"data-section","id":"panel-senales","children":[["$","div",null,{"className":"data-intro","children":[["$","h2",null,{"children":"Panel de señales"}],["$","p",null,{"children":"La lectura cualitativa se apoya en una capa cuantitativa acotada para contextualizar umbrales, dispersión y presión adversarial. Estas gráficas condensan patrones observables y su variación, sin pretender causalidad; funcionan como guía para revisar hipótesis antes de ajustar compuertas."}]]}],["$","div",null,{"className":"stat-grid","children":[["$","div",null,{"className":"stat-card","children":[["$","p",null,{"className":"stat-label","children":"Latencia de compuerta (p95)"}],["$","p",null,{"className":"stat-value","children":"12–18 ms"}],["$","p",null,{"className":"stat-note","children":"Ventana operativa para bloqueo antes de salida."}]]}],["$","div",null,{"className":"stat-card","children":[["$","p",null,{"className":"stat-label","children":"Cobertura residual (proxy)"}],["$","p",null,{"className":"stat-value","children":"~0.62"}],["$","p",null,{"className":"stat-note","children":"Mayor en fácticos, menor en rutas encubiertas."}]]}],["$","div",null,{"className":"stat-card","children":[["$","p",null,{"className":"stat-label","children":"Presión de estrés (relativa)"}],["$","p",null,{"className":"stat-value","children":"2.6×"}],["$","p",null,{"className":"stat-note","children":"Incremento relativo bajo suites adversariales."}]]}]]}],["$","$L7",null,{"lang":"es"}]]}],["$","article",null,{"className":"markdown","dangerouslySetInnerHTML":{"__html":"$8"}}],["$","section",null,{"className":"research-notes","children":[["$","h2",null,{"children":"Notas del investigador"}],["$","p",null,{"children":"Estas notas acompañan la lectura como registro de supuestos operativos y límites observados en revisión interna. La prioridad es mantener trazabilidad de decisiones de umbral, señales omitidas y dependencias de evaluación que pueden sesgar la interpretación de seguridad."}],["$","p",null,{"className":"note-signature","children":"Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves"}]]}],["$","footer",null,{"className":"article-footer","children":[["$","p",null,{"children":"Registro editorial reservado para circulación interna. La versión publicada puede variar según cambios de marco o terminología."}],["$","p",null,{"children":"Referencias y notas técnicas disponibles en el archivo principal. Autores: Ricardo Martinez, Fernando Valdovinos, Luis Cosio, Godric Aceves. Proyecto base: https://github.com/luiscosio/MechWatch.git."}]]}]]}]]}]
