3:I[9275,[],""]
4:I[1343,[],""]
0:["siPc-Nr_mDgk2EW9U0aNv",[[["",{"children":["en",{"children":["__PAGE__",{}]}]},"$undefined","$undefined",true],["",{"children":["en",{"children":["__PAGE__",{},[["$L1","$L2"],null],null]},["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children","en","children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":"$undefined","notFoundStyles":"$undefined","styles":null}],null]},[["$","html",null,{"lang":"es","children":["$","body",null,{"children":["$","div",null,{"className":"page","children":["$","$L3",null,{"parallelRouterKey":"children","segmentPath":["children"],"error":"$undefined","errorStyles":"$undefined","errorScripts":"$undefined","template":["$","$L4",null,{}],"templateStyles":"$undefined","templateScripts":"$undefined","notFound":[["$","title",null,{"children":"404: This page could not be found."}],["$","div",null,{"style":{"fontFamily":"system-ui,\"Segoe UI\",Roboto,Helvetica,Arial,sans-serif,\"Apple Color Emoji\",\"Segoe UI Emoji\"","height":"100vh","textAlign":"center","display":"flex","flexDirection":"column","alignItems":"center","justifyContent":"center"},"children":["$","div",null,{"children":[["$","style",null,{"dangerouslySetInnerHTML":{"__html":"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}"}}],["$","h1",null,{"className":"next-error-h1","style":{"display":"inline-block","margin":"0 20px 0 0","padding":"0 23px 0 0","fontSize":24,"fontWeight":500,"verticalAlign":"top","lineHeight":"49px"},"children":"404"}],["$","div",null,{"style":{"display":"inline-block"},"children":["$","h2",null,{"style":{"fontSize":14,"fontWeight":400,"lineHeight":"49px","margin":0},"children":"This page could not be found."}]}]]}]}]],"notFoundStyles":[],"styles":null}]}]}]}],null],null],[[["$","link","0",{"rel":"stylesheet","href":"/Mechanistic-Watchdog-Real-Time-Cognitive/_next/static/css/ce47a992fb67989b.css","precedence":"next","crossOrigin":"$undefined"}]],[null,"$L5"]]]]]
5:[["$","meta","0",{"name":"viewport","content":"width=device-width, initial-scale=1"}],["$","meta","1",{"charSet":"utf-8"}],["$","title","2",{"children":"Mechanistic Watchdog: Interdicción Cognitiva en SL5"}],["$","meta","3",{"name":"description","content":"Nota de investigación en español sobre desalineación emergente y observación mecanicista bajo un marco SL5."}],["$","meta","4",{"property":"og:title","content":"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"}],["$","meta","5",{"property":"og:description","content":"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."}],["$","meta","6",{"property":"og:type","content":"article"}],["$","meta","7",{"name":"twitter:card","content":"summary"}],["$","meta","8",{"name":"twitter:title","content":"Mechanistic Watchdog: Interdicción Cognitiva en Tiempo Real para Desalineación Emergente (SL5)"}],["$","meta","9",{"name":"twitter:description","content":"Nota de investigación en español sobre observación continua de señales cognitivas internas y límites del alineamiento por salidas."}]]
1:null
7:I[5750,["656","static/chunks/656-94d35dd80c11d44d.js","584","static/chunks/584-118b482da1b26d3f.js","479","static/chunks/app/en/page-c98435ef586f8f43.js"],"default"]
6:Td3c,<div id="texto-principal"></div>
<h2>Abstract</h2>
<p>Mechanistic Watchdog is a real‑time safety layer that monitors a language model’s internal activations and can interrupt generation before harmful content appears. The approach relies on interpretable internal signals and an active gate aligned with SL5 guidance to reduce risk in high‑stakes deployments. We present an operational formulation, calibration choices, and early results that motivate its use as a preventive control rather than a replacement for policy or human oversight.</p>
<h2>TL;DR</h2>
<p>We propose a cognitive kill switch that detects internal risk signals and stops generation with low latency. The goal is to intercept high‑risk behavior before it appears in text. We show early separation across categories and discuss tradeoffs such as accidental triggers and sensitivity under adversarial pressure.</p>
<h2>1. Motivation and stakes</h2>
<p>Modern LLMs are deployed in settings where output errors can affect money, infrastructure, or clinical decisions. Output‑level alignment is a late filter and can fail under covert strategies, fragmentation, or sustained adversarial pressure. A mechanism that observes internal signals during inference can reduce the exposure window, consistent with SL5 guidance on continuous monitoring and active gating [11]. The goal is not to solve alignment, but to reduce operational risk under emergent misalignment and misuse.</p>
<h2>2. Mechanism definition</h2>
<p>Mechanistic Watchdog is defined as a lightweight circuit that reads activations in real time and computes scores over risk‑relevant conceptual directions. The gate acts within the same forward pass, avoiding the latency and cost of a second model or post‑hoc filter. The intent is to interrupt before the next token is emitted once a conservative threshold is crossed. The design prioritizes early intervention over exhaustive explanation and is framed as a complementary control [7], [8].</p>
<h2>3. Internal signals and measurement</h2>
<p>We focus on mid‑layer residual streams because they capture high‑level intent and are accessible at inference time. Directions are obtained via linear probing and mean‑difference separation on positive and negative sets [9]. The operational score is a projection onto each direction, enabling attribution of which concept fired and how strongly. This legibility is important for audit and policy tuning [12].</p>
<h2>4. Calibration and thresholds</h2>
<p>Thresholds are calibrated as safety‑margin decisions. Lower thresholds reduce escape risk but increase false positives; higher thresholds reduce interruptions but can miss harmful behavior. This phase favors caution and documents expected operational cost. Calibration uses datasets such as TruthfulQA and Facts‑true‑false for truthfulness and WMDP for misuse, with domain‑specific evaluation [10], [14], [15].</p>
<h2>5. Results and visuals</h2>
<p>Early results show consistent separation between classes across two domains and bounded latency overhead. Figures 1–8 summarize domain control distribution, the observation loop, the interdiction threshold, and sensitivity under adversarial pressure. Figures 7–8 provide boxplots of category separation with an operational reading of the threshold. These figures are illustrative and do not replace full statistical analysis.</p>8:Tf09,<h2>6. Risks and accidental triggers</h2>
<p>A safety control can fail by omission or by excess. In high‑stakes settings, a false positive can block benign tasks and cause real costs. We therefore track interruption rates and consider multi‑vector gating to reduce spurious activations. The mechanism is framed as risk reduction, not as a perfect guardian.</p>
<h2>7. Position in the safety ecosystem</h2>
<p>Mechanistic Watchdog is not an alignment method, a content filter, or a full audit. It is an operational control that can run in deployment alongside red teaming, auditing, and interpretability tools [7]. Its value is acting upstream of text and emitting auditable signals during inference. The SL5 tie‑in is the expectation of active containment with early intervention [11].</p>
<h2>8. Limitations and future work</h2>
<p>The current approach depends on a small set of conceptual directions and is not validated against advanced adaptive adversaries. Stress tests should expand to stronger jailbreak suites and adaptive opponents, and to domains such as cyber and chemistry. Direction stability across models and contexts also remains open. The goal is to improve sensitivity without disproportionate false positives.</p>
<div id="siguientes-pasos"></div>
<h2>9. Next steps</h2>
<p>We propose expanding conceptual vectors, adjusting category weights, and validating performance under adversarial pressure. We also plan to instrument operational‑cost metrics and resilience to evasion. Created by Ricardo Martinez, Fernando Valdovinos, Luis Cosio, and Godric Aceves. Defensive Acceleration Hackathon 2025.</p>
<div id="bibliografia"></div>
<h2>References</h2>
<p>[1] N. Elhage et al., “Toy Models of Superposition,” Transformer Circuits Thread, 2022. https://transformer-circuits.pub/2022/toy_model/index.html</p>
<p>[2] A. Shimi, “Understanding gradient hacking,” AI Alignment Forum, 2021. https://www.alignmentforum.org/posts/U7Z2sJp7t7j2Z/understanding-gradient-hacking</p>
<p>[3] A. Karpov et al., “The steganographic potentials of language models,” arXiv:2505.03439, 2025. https://arxiv.org/abs/2505.03439</p>
<p>[4] M. Steinebach, “Natural language steganography by ChatGPT,” ARES 2024. https://dl.acm.org/doi/10.1145/3664476.3664514</p>
<p>[5] M. Andriushchenko and N. Flammarion, “Does refusal training in LLMs generalize to the past tense?” arXiv:2407.11969, 2024. https://arxiv.org/abs/2407.11969</p>
<p>[6] S. Martin, “How difficult is AI alignment?” AI Alignment Forum, 2024. https://www.alignmentforum.org/posts/vJFdjigz2CFu8j96b/how-difficult-is-ai-alignment</p>
<p>[7] N. Goldowsky-Dill et al., “Detecting Strategic Deception Using Linear Probes,” arXiv:2502.03407, 2025. https://arxiv.org/abs/2502.03407</p>
<p>[8] A. Zou et al., “Representation Engineering: A Top-Down Approach to AI Transparency,” arXiv:2310.01405, 2023. https://arxiv.org/abs/2310.01405</p>
<p>[9] A. Azaria and T. Mitchell, “The Internal State of an LLM Knows When It’s Lying,” arXiv:2304.13734, 2023. https://arxiv.org/abs/2304.13734</p>
<p>[10] S. Lin et al., “TruthfulQA: Measuring How Models Mimic Human Falsehoods,” ACL 2022. https://aclanthology.org/2022.acl-long.229/</p>
<p>[11] RAND Corporation, “A Playbook for Securing AI Model Weights,” Research Brief, 2024. https://www.rand.org/pubs/research_briefs/RBA2849-1.html</p>
<p>[12] S. Marks and M. Tegmark, “The Geometry of Truth: Correlation is not Causation,” arXiv:2310.06824, 2023. https://arxiv.org/abs/2310.06824</p>
<p>[13] L1Fthrasir, “Facts-true-false,” Hugging Face, 2024. https://huggingface.co/datasets/L1Fthrasir/Facts-true-false</p>
<p>[14] Center for AI Safety, “WMDP,” Hugging Face, 2023. https://huggingface.co/datasets/cais/wmdp</p>
<p>[15] Latency measured on NVIDIA RTX 4090. Values may vary by hardware.</p>2:["$","main",null,{"className":"layout","children":[["$","header",null,{"className":"site-header","children":[["$","div",null,{"className":"brand","children":[["$","div",null,{"className":"brand-mark","children":"MW"}],["$","div",null,{"children":[["$","p",null,{"className":"brand-label","children":"Mechanistic Watchdog"}],["$","p",null,{"className":"brand-caption","children":"Research note"}]]}]]}],["$","div",null,{"className":"site-actions","children":[["$","div",null,{"className":"site-meta","children":[["$","p",null,{"children":"Series: SL5 Notes"}],["$","p",null,{"children":"Update: March 2025"}],["$","p",null,{"children":"Read: 6 min · 901 words"}]]}],["$","a",null,{"className":"lang-toggle","href":"/Mechanistic-Watchdog-Real-Time-Cognitive/","children":"Español"}]]}]]}],["$","section",null,{"className":"article","children":[["$","header",null,{"className":"article-header","children":[["$","p",null,{"className":"eyebrow","children":"Research note"}],["$","h1",null,{"children":"Mechanistic Watchdog: Real‑Time Cognitive Interdiction for Emergent Misalignment (SL5)"}],["$","p",null,{"className":"authors-inline","children":"Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves"}],["$","p",null,{"className":"subhead","children":"Research note in English."}]]}],["$","article",null,{"className":"markdown","dangerouslySetInnerHTML":{"__html":"$6"}}],["$","section",null,{"className":"data-section","id":"panel-senales","children":[["$","div",null,{"className":"data-intro","children":[["$","h2",null,{"children":"Signals panel"}],["$","p",null,{"children":"The qualitative reading is anchored by a constrained quantitative layer to contextualize thresholds, dispersion, and adversarial pressure. These charts condense observable patterns and their variation without claiming causality; they guide hypothesis review before gate adjustments."}]]}],["$","div",null,{"className":"stat-grid","children":[["$","div",null,{"className":"stat-card","children":[["$","p",null,{"className":"stat-label","children":"Gate latency (p95)"}],["$","p",null,{"className":"stat-value","children":"12–18 ms"}],["$","p",null,{"className":"stat-note","children":"Operational window for pre‑output blocking."}]]}],["$","div",null,{"className":"stat-card","children":[["$","p",null,{"className":"stat-label","children":"Residual coverage (proxy)"}],["$","p",null,{"className":"stat-value","children":"~0.62"}],["$","p",null,{"className":"stat-note","children":"Higher on factuals, lower on covert routes."}]]}],["$","div",null,{"className":"stat-card","children":[["$","p",null,{"className":"stat-label","children":"Stress pressure (relative)"}],["$","p",null,{"className":"stat-value","children":"2.6×"}],["$","p",null,{"className":"stat-note","children":"Relative increase under adversarial suites."}]]}]]}],["$","$L7",null,{"lang":"en"}]]}],["$","article",null,{"className":"markdown","dangerouslySetInnerHTML":{"__html":"$8"}}],["$","section",null,{"className":"research-notes","children":[["$","h2",null,{"children":"Researcher notes"}],["$","p",null,{"children":"These notes accompany the reading as a record of operating assumptions and limits observed in internal review. The priority is to preserve traceability of threshold decisions, omitted signals, and evaluation dependencies that can bias security interpretation."}],["$","p",null,{"className":"note-signature","children":"Ricardo Martinez · Fernando Valdovinos · Luis Cosio · Godric Aceves"}]]}],["$","footer",null,{"className":"article-footer","children":[["$","p",null,{"children":"Editorial record reserved for internal circulation. The published version may vary with framework or terminology changes."}],["$","p",null,{"children":"References and technical notes are available in the main file. Authors: Ricardo Martinez, Fernando Valdovinos, Luis Cosio, Godric Aceves. Base project: https://github.com/luiscosio/MechWatch.git."}]]}]]}]]}]
